{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "299cf688",
      "metadata": {
        "id": "299cf688"
      },
      "source": [
        "# Pr谩ctica 2 - Multy Layered Perceptron\n",
        "## Introducci贸n\n",
        "\n",
        "El Perceptr贸n Multicapa (MLP) se denomina una red neuronal multicapa totalmente conectada.\n",
        "\n",
        "Tiene 3 capas, incluida una capa oculta. Si tiene m谩s de 1 capa oculta, se denomina una red neuronal profunda. Un MLP es un ejemplo t铆pico de una red neuronal *feedforward*.\n",
        "\n",
        "El n煤mero de capas y el n煤mero de neuronas se conocen como hiperpar谩metros de una red neuronal, y estos necesitan ajuste. Se deben utilizar t茅cnicas de validaci贸n cruzada para encontrar valores ideales para estos.<sup>[1][1]</sup>\n",
        "\n",
        "![MLP Neural Network](https://www.researchgate.net/profile/Manouchehr_Shokri/publication/339032619/figure/download/fig1/AS:854994186170369@1580857907467/Structure-of-typical-MLP-artificial-neural-network.ppm \"MLP Neural Network\")\n",
        "\n",
        "### Modelo Predictivo\n",
        "\n",
        "En esta pr谩ctica, la Funci贸n de Activaci贸n es, de nuevo, un **Hard Limiter** (o Funci贸n Escal贸n, en este caso, tenemos 2: ReLU<sup>[2][2]</sup> y sigmoide<sup>[3][3]</sup>) cuya expresi贸n general ser谩:\n",
        "\n",
        "> ReLu:\n",
        ">\n",
        "> $$ \\begin{equation*}{F(S,\\theta)} = \\begin{cases}F, \\text{si } F >=0\\\\0, \\text{si } F < 0 \\end{cases}\\end{equation*}$$\n",
        ">\n",
        "> Sigmoide\n",
        "> $$ \\begin{equation*}{F(S,\\theta)} = \\frac{1}{1 + e^{-S}}\\end{equation*}$$\n",
        ">\n",
        "\n",
        "### Optimizer\n",
        "El aprendizaje en este caso, en vez de seguir la **Regla Delta Generalizada**, tomaremos **Adam**<sup>[4][4]</sup> como funci贸n de modificaci贸n:\n",
        "\n",
        "<br>\n",
        "\n",
        "Adam:\n",
        "\n",
        "> $${\\displaystyle m_{t}=\\beta _{1}*m_{t}+(1-\\beta _{1})*(\\delta L/\\delta w_{t})}$$\n",
        "\n",
        "<center>y</center>\n",
        "\n",
        "> $${\\displaystyle v_{t}=\\beta _{2}*v_{t}+(1-\\beta _{2})*(\\delta L/\\delta w_{t})^{2}}$$\n",
        "\n",
        "Inicialmente, tanto ${mt}$ como ${vt}$ se establecen en 0. Ambos tienden a estar m谩s sesgados hacia 0, ya que ${\\beta_{1}}$ y ${\\beta_{2}}$ son iguales a 1. Al calcular con correcci贸n de sesgo ${\\displaystyle {\\hat {m_{t}}}}{\\displaystyle {\\hat {m_{t}}}}$ y ${\\displaystyle {\\hat {v_{t}}}}{\\displaystyle {\\hat {v_{t}}}}$, el optimizador de Adam corrige este problema. Las ecuaciones son las siguientes\n",
        "\n",
        "> $${\\displaystyle {\\hat {m_{t}}}=m_{t}\\div (1-\\beta _{1}^{t})}{\\displaystyle {\\hat {m_{t}}}=m_{t}\\div (1-\\beta _{1}^{t})}$$\n",
        ">\n",
        "> $${\\displaystyle {\\hat {v_{t}}}=v_{t}\\div (1-\\beta _{2}^{t})}{\\displaystyle {\\hat {v_{t}}}=v_{t}\\div (1-\\beta _{2}^{t})}$$\n",
        "\n",
        "Ahora nos estamos acostumbrando al descenso de gradiente despu茅s de cada iteraci贸n y, por tanto, permanece controlado e imparcial. Ahora sustituimos los nuevos par谩metros en por antiguos. Obtenemos;\n",
        "\n",
        "> $${\\displaystyle w_{t}=w(t-1)-\\alpha *({\\hat {m_{t}}}/{\\sqrt {(}}{\\hat {v_{t}}})+e)}$$\n",
        "\n",
        "El pseudoc贸digo para el optimizador de Adam se proporciona a continuaci贸n:\n",
        "\n",
        "> **While** w(t) no converge **do**:\n",
        ">\n",
        "> ${\\displaystyle t=t+1.}{\\displaystyle t=t+1.}$\n",
        ">\n",
        "> ${\\displaystyle m_{t}=\\beta _{1}*m_{t}+(1-\\beta _{1})*(\\delta L/\\delta w_{t})}$\n",
        ">\n",
        "> ${\\displaystyle v_{t}=\\beta _{2}*v_{t}+(1-\\beta _{2})*(\\delta L/\\delta w_{t})^{2}}$\n",
        ">\n",
        "> ${\\displaystyle {\\hat {m_{t}}}=m_{t}\\div (1-\\beta _{1}^{t})}{\\displaystyle {\\hat {m_{t}}}=m_{t}\\div (1-\\beta _{1}^{t})}$\n",
        ">\n",
        "> ${\\displaystyle {\\hat {v_{t}}}=v_{t}\\div (1-\\beta _{2}^{t})}{\\displaystyle {\\hat {v_{t}}}=v_{t}\\div (1-\\beta _{2}^{t})}$\n",
        ">\n",
        "> ${\\displaystyle w_{t}=w(t-1)-\\alpha *({\\hat {m_{t}}}/{\\sqrt {(}}{\\hat {v_{t}}})+e)}$\n",
        ">\n",
        "> **end**\n",
        "\n",
        "<br>\n",
        "\n",
        "Error (Mean Squared Error):\n",
        "\n",
        "> $$ e = \\frac{({Y_t} - {d_t})^2}{n} $$\n",
        "\n",
        "<!-- Referencias Introductorias -->\n",
        "\n",
        "[1]: <https://www.simplilearn.com/tutorials/deep-learning-tutorial/multilayer-perceptron> \"MLP\"\n",
        "[2]: <https://iq.opengenus.org/relu-activation/> \"ReLU\"\n",
        "[3]: <https://deepai.org/machine-learning-glossary-and-terms/sigmoid-function#:~:text=A%20sigmoid%20function%20is%20a%20type%20of%20activation,these%20functions%20useful%20in%20the%20prediction%20of%20probabilities.> \"Sigmoide\"\n",
        "[4]: <https://optimization.cbe.cornell.edu/index.php?title=Adam> \"Adam\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a3075d4",
      "metadata": {
        "id": "3a3075d4"
      },
      "source": [
        "## Implementaci贸n\n",
        "### Importar librer铆as de c贸digo\n",
        "\n",
        "En nuestro caso hemos reducido al m铆nimo el n煤mero de librer铆as de c贸digo a utilizar para esta pr谩ctica; en nuestro caso utilizamos las siguientes:\n",
        "\n",
        "- <ins>Tensorflow</ins> &rarr; TensorFlow es una biblioteca de software gratuita y de c贸digo abierto para el aprendizaje autom谩tico y la inteligencia artificial. Utilizamos Tensorflow para:\n",
        "  - Modelos de Keras:\n",
        "    - Creaci贸n \n",
        "    - Entrenamiento \n",
        "    - Validaci贸n \n",
        "  - Visualizaci贸n de modelos \n",
        "- <ins>IPython</ins> &rarr; IPython es un shell de comandos para computaci贸n interactiva en m煤ltiples lenguajes de programaci贸n, desarrollado originalmente para el lenguaje de programaci贸n Python. Utilizamos IPython para:\n",
        "  - Creaci贸n y visualizaci贸n de im谩genes \n",
        "- <ins>Numpy</ins> &rarr; Es una librer铆a num茅rica que trae el poder computacional de lenguajes como C y Fortran a Python. Utilizamos Numpy para:\n",
        "  - Utilizar arrays \n",
        "  - Generar n煤meros aleatorios \n",
        "  - Generar arrays a partir de distribuciones num茅ricas \n",
        "- <ins>Pandas</ins> &rarr; Es una librer铆a de manipulaci贸n y an谩lisis de datos de c贸digo abierto r谩pida, potente, flexible y f谩cil de usar, construida sobre el lenguaje de programaci贸n Python. Usamos Pandas para:\n",
        "  - Abrir archivos .csv \n",
        "  - Dataframes \n",
        "- <ins>Matplotlib</ins> &rarr; Es una librer铆a para crear visualizaciones est谩ticas, animadas e interactivas en Python. Usamos Matplotlib para:\n",
        "  - Mostrar gr谩ficos \n",
        "  - Tipo de renderizado `inline`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ee1293-0cfb-417d-8d83-1f8d3b83812f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ee1293-0cfb-417d-8d83-1f8d3b83812f",
        "outputId": "941521eb-0e5f-4a55-b070-b9ecaf0755be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versiones de las librer铆as con las que vamos a trabajar:\n",
            "\tTensorflow y Keras\t>>> \tv 2.11.0\n",
            "\tNumpy\t\t\t>>> \tv 1.22.4\n",
            "\tPandas\t\t\t>>> \tv 1.4.4\n",
            "\tSklearn\t\t\t>>> \tv 1.2.2\n"
          ]
        }
      ],
      "source": [
        "print('Versiones de las librer铆as con las que vamos a trabajar:')\n",
        "# Librer铆as para redes neuronales\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as ks\n",
        "from tensorflow.keras import layers as ly\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "print('\\tTensorflow y Keras\\t>>> \\tv', tf.__version__)\n",
        "\n",
        "# !conda install -c anaconda graphviz\n",
        "# !conda install -c conda-forge pydot\n",
        "# ^ para ks.utils.plot_model ^\n",
        "\n",
        "# Librer铆a numn茅rica\n",
        "import numpy as np\n",
        "print('\\tNumpy\\t\\t\\t>>> \\tv', np.__version__)\n",
        "# Librer铆as para estructuras de datos\n",
        "import pandas as pd\n",
        "print('\\tPandas\\t\\t\\t>>> \\tv', pd.__version__)\n",
        "import sklearn as sk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('\\tSklearn\\t\\t\\t>>> \\tv', sk.__version__)\n",
        "# Librer铆a gr谩fica\n",
        "import matplotlib as mplt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print('\\tMatplotlib\\t\\t\\t>>> \\tv', mplt.__version__)\n",
        "# Ignorar Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparamos las variables para el XOR\n",
        "\n",
        "Volviendo a ver lo que hemos visto en la pr谩ctica anterior (el archivo L2P1_Perceptron.ipynb), las entradas son:\n",
        "\n",
        "| $x_{1}$ | $x_{2}$ | $y$ |\n",
        "|---------|---------|-----|\n",
        "| 0       | 0       | 0   |\n",
        "| 0       | 1       | 1   |\n",
        "| 1       | 0       | 1   |\n",
        "| 1       | 1       | 0   |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LuR8R0NxNE9v"
      },
      "id": "LuR8R0NxNE9v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b682804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b682804",
        "outputId": "d9a0310f-96e5-4167-cc66-13e02c388587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteraciones:\n",
            " [  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n",
            "  95 100]\n",
            "\n",
            "Entradas:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "\n",
            "Salidas:\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "# Epochs\n",
        "iters = np.array(range(5,101,5))\n",
        "print('Iteraciones:\\n', iters)\n",
        "# Matriz que almacena las posibles entradas de una funci贸n l贸gica\n",
        "entradas = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "print('\\nEntradas:\\n', entradas)\n",
        "# Vector de salidas esperadas de la funci贸n XOR\n",
        "salidas = np.array([[0], [1], [1], [0]])\n",
        "print('\\nSalidas:\\n', salidas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f14e9e",
      "metadata": {
        "id": "a2f14e9e"
      },
      "source": [
        "### N煤mero de Neuronas\n",
        "\n",
        "- Entrada > Tantas como patrones de entrada (XOR = 2)\n",
        "- Salida > Tantas como salidas esperadas (XOR = 1)\n",
        "- Totales > Menor que el n煤mero de patrones de entrenamiento\n",
        "- Intermedia > Muchas overfitting y pocas underfitting; y, emp铆ricamente, $\\frac{M}{2N}<n<\\frac{2M}{N}$; donde M es el n煤mero de ejemplos y N de neuronas en la capa de entrada\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos el rango en el que trabajaremos las neuronas\n",
        "neuronas = range(int(entradas.shape[0]/(2*entradas.shape[1]))+1,int((2*entradas.shape[0])/entradas.shape[1]))\n",
        "neuronas = np.array(neuronas)\n",
        "# Posibles funciones de activaci贸n\n",
        "funciones_activacion = ['relu','sigmoid']"
      ],
      "metadata": {
        "id": "dCrzWR56SA3A"
      },
      "id": "dCrzWR56SA3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuraci贸n de modelos"
      ],
      "metadata": {
        "id": "FVG4qNR7Uy6U"
      },
      "id": "FVG4qNR7Uy6U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672eb5f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "672eb5f1",
        "outputId": "828c5cb7-0e60-4a8d-86f5-5999ea532c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurar Modelos (podemos ver los modelos en la carpeta Visualizar_Modelos)\n",
            "=================================================================\n",
            "Model: \"2nHreluOrelu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 2)                 6         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"2nHreluOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 2)                 6         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"2nHsigmoidOrelu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 2)                 6         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"2nHsigmoidOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 2)                 6         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"3nHreluOrelu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"3nHreluOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"3nHsigmoidOrelu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n",
            "Model: \"3nHsigmoidOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Como tenemos 4 patrones de entrenamiento, el valor de la capa intermedia\n",
        "# (o capa oculta) solo puede ser 2 o 3, como nos da la f贸rmula emp铆rica vista\n",
        "# arriba\n",
        "def _createModel(n:int, f_a_hidden:str, f_a_output:str):\n",
        "    # Creamos un modelo Secuencial con capas \"Fully Connected\" (Dense) para crear la\n",
        "    # estructura del Perceptron Multicapa\n",
        "    modelo_MLP = ks.models.Sequential([\n",
        "        ly.InputLayer(input_shape=(entradas.shape[1],), name='Input_Layer'), # Capa de entrada con la forma del n煤mero de clases del dataset de entradas (la funci贸n l贸gica)\n",
        "        ly.Dense(n, activation=f_a_hidden, name='Hidden_Layer'), # Unas sola capa oculta basandonos en el Teorema de Aproximaci贸n Universal con las neuronas vistas anteriormente\n",
        "        ly.Dense(salidas.shape[1], activation=f_a_output, name='Output_Layer') # Una capa de salida con con la forma del n煤mero de columnas del dataset de salidas (la funci贸n l贸gica)\n",
        "    ], name=str(n) + 'nH' + f_a_hidden + 'O' + f_a_output) # Nombramos el modelo acorde a su configuraci贸n 'Num_Neuronas'n'Func_Activaci贸n_Hidden'H'Func_Activaci贸n_Output'O\n",
        "    return modelo_MLP\n",
        "\n",
        "# Creamos una lista para almacenar los modelos\n",
        "modelos_MLP = []\n",
        "print('Configurar Modelos (podemos ver los modelos en la carpeta Visualizar_Modelos)\\n=================================================================')\n",
        "# Creamos los modelos con las diferentes configuraciones obtenidas previamente\n",
        "for i in range(0,len(neuronas)):\n",
        "    for j in range(0, len(funciones_activacion)):\n",
        "        for k in range(0, len(funciones_activacion)):\n",
        "            # Almacenamos el modelo configurado\n",
        "            modelos_MLP.append(_createModel(neuronas[i],funciones_activacion[j],funciones_activacion[k]))\n",
        "\n",
        "# Mostramos los datos de los modelos y creamos visualizaciones de los mismos\n",
        "for n in range(0, len(modelos_MLP)):\n",
        "    modelos_MLP[n].summary()\n",
        "    # Creamos la im谩gen\n",
        "    \"\"\"ks.utils.plot_model(\n",
        "        modelos_MLP[n],\n",
        "        to_file='Visualizar_Modelos/model_'+ str(n) +'.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True,\n",
        "        expand_nested=True,\n",
        "        dpi=100,\n",
        "        show_layer_activations=True, # Funcionar谩 si la versi贸n de tensorflow es superior a v2.7.0, recomendado dejar comentado\n",
        "        )\"\"\"\n",
        "    print('\\n=================================================================\\n')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparaci贸n para el entrenamiento de los modelos\n",
        "\n",
        "Utilizamos el optimizador Adam y para el optimizador dejamos los valores por defecto; centrandonos en buscar la mejor combinaci贸n para un modelo de:\n",
        "\n",
        "   - pocas (epoch) o iteraciones\n",
        "   - N煤mero de neuronas\n",
        "   - Funciones de activaci贸n"
      ],
      "metadata": {
        "id": "cZYWForOVyth"
      },
      "id": "cZYWForOVyth"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2fd252",
      "metadata": {
        "id": "9c2fd252"
      },
      "outputs": [],
      "source": [
        "# Optimizador Adam con configuraci贸n por defecto\n",
        "opt = ks.optimizers.legacy.Adam()\n",
        "# Funci贸n de error de Mean Sqared Error\n",
        "error = ks.losses.MeanSquaredError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introducimos la configuraci贸n del modelo para el entrenamiento"
      ],
      "metadata": {
        "id": "ap_fiDWIZ22l"
      },
      "id": "ap_fiDWIZ22l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cb522d",
      "metadata": {
        "id": "75cb522d"
      },
      "outputs": [],
      "source": [
        "# Conpilamos los modelos con el optimizador y error anterior\n",
        "for i in range(0, len(modelos_MLP)):\n",
        "          modelos_MLP[i].compile(optimizer=opt, loss=error, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenar, evaluar y predecir\n",
        "\n",
        "En esta celda, entrenamos el modelo para cada uno de los posibles valores que puede tener (en cuanto lo mencionado anteriormente) con `model.fit()`\n",
        "\n",
        "Cuando entrenamos un modelo, adem谩s:\n",
        "\n",
        "  - Lo evaluamos con `model.evaluate()`\n",
        "  - Predecimos nuevos valores `model.predict()`\n",
        "\n",
        "Cabe decir que, en el caso de este dataset, no dividimos el mismo entre datos de entrenamiento y de validaci贸n debido a la poca cantidad de ejemplos con los que contamos."
      ],
      "metadata": {
        "id": "o0V4o0srZ_bI"
      },
      "id": "o0V4o0srZ_bI"
    },
    {
      "cell_type": "code",
      "source": [
        "model = _createModel(3,'relu', 'sigmoid')\n",
        "model.compile(optimizer=opt, loss=error, metrics=['accuracy'])\n",
        "history = model.fit(x=entradas, y=salidas, batch_size=entradas.shape[0], epochs=10)\n",
        "model.evaluate(x=entradas, y=salidas, batch_size=entradas.shape[0])\n",
        "model.predict(x=entradas, batch_size=entradas.shape[0])\n",
        "history.history['loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZAFGzukYMrR",
        "outputId": "af9263de-f2bf-49ac-cf24-5d28f7e192ac"
      },
      "id": "MZAFGzukYMrR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3324 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3319 - accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3313 - accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3308 - accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3302 - accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3297 - accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3291 - accuracy: 0.2500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3286 - accuracy: 0.2500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3280 - accuracy: 0.2500\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3275 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.3269 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 208ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33239951729774475,\n",
              " 0.33185216784477234,\n",
              " 0.33130520582199097,\n",
              " 0.33075857162475586,\n",
              " 0.3302123248577118,\n",
              " 0.3296664357185364,\n",
              " 0.329120934009552,\n",
              " 0.32857581973075867,\n",
              " 0.32803112268447876,\n",
              " 0.32748690247535706]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c1c36e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48c1c36e",
        "outputId": "a54c64c6-ac00-4304-8cd4-b713e49342da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las 煤ltimas 5000 l铆neas del flujo de salida.\u001b[0m\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 59/85\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 60/85\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 61/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 62/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 63/85\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 64/85\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 65/85\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 66/85\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 67/85\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 68/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 69/85\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 70/85\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 71/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 72/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 73/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 74/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 75/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 76/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 77/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 78/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 79/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 80/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 81/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 82/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 83/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 84/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 85/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "=====================================================================\n",
            "Para el modelo 6潞 con 90 epochs\n",
            "Epoch 1/90\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 2/90\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 3/90\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 4/90\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 5/90\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 6/90\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 7/90\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 8/90\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 9/90\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 10/90\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 11/90\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 12/90\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 13/90\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 14/90\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 15/90\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 16/90\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 17/90\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 18/90\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 19/90\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 20/90\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 21/90\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 22/90\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 23/90\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 24/90\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 25/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 26/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 27/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 28/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 29/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 30/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 31/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 32/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 33/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 34/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 35/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 36/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 37/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 38/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 39/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 40/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 41/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 42/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 43/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 44/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 45/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 46/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 47/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 48/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 49/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 50/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 51/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 52/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 53/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 54/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 55/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 56/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 57/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 58/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 59/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 60/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 61/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 62/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 63/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 64/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 65/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 66/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 67/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 68/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 69/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 70/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 71/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 72/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 73/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 74/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 75/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 76/90\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 77/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 78/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 79/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 80/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 81/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 82/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 83/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 84/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 85/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 86/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 87/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 88/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 89/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 90/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "=====================================================================\n",
            "Para el modelo 6潞 con 95 epochs\n",
            "Epoch 1/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 2/95\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 3/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 4/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 5/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 6/95\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 7/95\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 8/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 9/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 10/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 11/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 12/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 13/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 14/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 15/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 16/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 17/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 18/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 19/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 20/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 21/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 22/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 23/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 24/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 25/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 26/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 27/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 28/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 29/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 30/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 31/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 32/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 33/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 34/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 35/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 36/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 37/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 38/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 39/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 40/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 41/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 42/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 43/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 44/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 45/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 46/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 47/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 48/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 49/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 50/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 51/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 52/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 53/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 54/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 55/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 56/95\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 57/95\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 58/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 59/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 60/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 61/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 62/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 63/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 64/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 65/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 66/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 67/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 68/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 69/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 70/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 71/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 72/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 73/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 74/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 75/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 76/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 77/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 78/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 79/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 80/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 81/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 82/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 83/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 84/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 85/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 86/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 87/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 88/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 89/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 90/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 91/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 92/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 93/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 94/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 95/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "=====================================================================\n",
            "Para el modelo 6潞 con 100 epochs\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 5 epochs\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 10 epochs\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 15 epochs\n",
            "Epoch 1/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 20 epochs\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 25 epochs\n",
            "Epoch 1/25\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/25\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/25\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 30 epochs\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 35 epochs\n",
            "Epoch 1/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/35\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/35\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/35\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/35\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 40 epochs\n",
            "Epoch 1/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/40\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 45 epochs\n",
            "Epoch 1/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/45\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/45\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 50 epochs\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 55 epochs\n",
            "Epoch 1/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/55\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/55\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 60 epochs\n",
            "Epoch 1/60\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/60\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/60\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/60\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/60\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/60\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/60\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 65 epochs\n",
            "Epoch 1/65\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/65\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/65\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/65\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/65\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/65\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/65\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/65\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 70 epochs\n",
            "Epoch 1/70\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/70\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/70\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/70\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/70\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/70\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/70\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 75 epochs\n",
            "Epoch 1/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 80 epochs\n",
            "Epoch 1/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/80\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/80\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/80\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/80\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/80\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/80\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/80\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 85 epochs\n",
            "Epoch 1/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/85\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/85\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/85\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 76/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 77/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 78/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 79/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 80/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 81/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 82/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 83/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 84/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 85/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 90 epochs\n",
            "Epoch 1/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 76/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 77/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 78/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 79/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 80/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 81/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 82/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 83/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 84/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 85/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 86/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 87/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 88/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 89/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 90/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 95 epochs\n",
            "Epoch 1/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/95\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/95\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 76/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 77/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 78/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 79/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 80/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 81/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 82/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 83/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 84/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 85/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 86/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 87/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 88/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 89/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 90/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 91/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 92/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 93/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 94/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 95/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "=====================================================================\n",
            "Para el modelo 7潞 con 100 epochs\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5000 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 5 epochs\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.2787 - accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2779 - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2769 - accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2757 - accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2745 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2731 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 10 epochs\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2731 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2718 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2705 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2691 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2666 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2654 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2642 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2631 - accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2620 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2610 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 15 epochs\n",
            "Epoch 1/15\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2610 - accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2601 - accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2592 - accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2584 - accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2576 - accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2569 - accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2557 - accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2542 - accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2537 - accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2533 - accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2530 - accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2524 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 20 epochs\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2522 - accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2519 - accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2517 - accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2513 - accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2511 - accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2510 - accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2510 - accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2509 - accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2508 - accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2507 - accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2507 - accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2506 - accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 25 epochs\n",
            "Epoch 1/25\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2505 - accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 14/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 18/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 19/25\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 20/25\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 21/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 23/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 24/25\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 25/25\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 30 epochs\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2503 - accuracy: 0.5000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 35 epochs\n",
            "Epoch 1/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 2/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 3/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 4/35\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 5/35\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 6/35\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 7/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 8/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 9/35\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 10/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 11/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 12/35\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 13/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 14/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 15/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 16/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 17/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 18/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 19/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 20/35\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 21/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 22/35\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 23/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 24/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 25/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 26/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 27/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 28/35\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 29/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.5000\n",
            "Epoch 30/35\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 31/35\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 32/35\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 33/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 34/35\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 35/35\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 40 epochs\n",
            "Epoch 1/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 5/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 6/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 7/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 8/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 9/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 10/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 11/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 12/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 13/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 14/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 15/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 16/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 17/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 18/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 19/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 20/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 21/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 22/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 23/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 25/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 26/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 27/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 28/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 29/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 30/40\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 31/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.5000\n",
            "Epoch 33/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 34/40\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 35/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 36/40\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 37/40\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 38/40\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 39/40\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 40/40\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 45 epochs\n",
            "Epoch 1/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 2/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 3/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 4/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 5/45\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 6/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 7/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 8/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 9/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 10/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 11/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 12/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 13/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 14/45\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 15/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 16/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 17/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 18/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 19/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 20/45\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 21/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 22/45\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 23/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 24/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 25/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 26/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 27/45\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 28/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 29/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 30/45\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 31/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 32/45\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 33/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - accuracy: 0.5000\n",
            "Epoch 34/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 35/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 36/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 37/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 38/45\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 39/45\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 40/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 41/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 42/45\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 43/45\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 44/45\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 45/45\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 50 epochs\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 55 epochs\n",
            "Epoch 1/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 2/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 3/55\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2498 - accuracy: 0.5000\n",
            "Epoch 4/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.2500\n",
            "Epoch 5/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.2500\n",
            "Epoch 6/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.2500\n",
            "Epoch 7/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2498 - accuracy: 0.2500\n",
            "Epoch 8/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.2500\n",
            "Epoch 9/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 10/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 11/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 12/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 13/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 14/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 15/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 16/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 17/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 18/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 19/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 20/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 21/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 22/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 23/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 24/55\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 25/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 26/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 27/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 28/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 29/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 30/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 31/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 32/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 33/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 34/55\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 35/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.2500\n",
            "Epoch 36/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 37/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 38/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 39/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 40/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 41/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 42/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.2500\n",
            "Epoch 43/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 44/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 45/55\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 46/55\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 47/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 48/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 49/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 50/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 51/55\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 52/55\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 53/55\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 54/55\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 55/55\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 60 epochs\n",
            "Epoch 1/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 3/60\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 4/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 5/60\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 6/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 7/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 8/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 9/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 10/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 11/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 12/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 13/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 14/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 15/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 16/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 17/60\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 18/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 19/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 20/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 21/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 22/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.5000\n",
            "Epoch 23/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 24/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 25/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 26/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 27/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 28/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 29/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 30/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 31/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 32/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 33/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 34/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 35/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 36/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 37/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 38/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.5000\n",
            "Epoch 39/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 40/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 41/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 42/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 43/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 44/60\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 45/60\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 46/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 47/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 48/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 49/60\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 50/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 51/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 52/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 53/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2492 - accuracy: 0.5000\n",
            "Epoch 54/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.5000\n",
            "Epoch 55/60\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 56/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 57/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 58/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 59/60\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 60/60\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 65 epochs\n",
            "Epoch 1/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 2/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 3/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 4/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 5/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.7500\n",
            "Epoch 6/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 7/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 8/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 9/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 10/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 11/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 12/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 13/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 14/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 15/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 16/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.7500\n",
            "Epoch 17/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 18/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 19/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 20/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 21/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 22/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 23/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 24/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 25/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 26/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 27/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.7500\n",
            "Epoch 28/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 29/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 30/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 31/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 32/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 33/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 34/65\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 35/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 36/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.7500\n",
            "Epoch 37/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 38/65\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 39/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 40/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 41/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 42/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 43/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 44/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 45/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2488 - accuracy: 0.7500\n",
            "Epoch 46/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 47/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 48/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 49/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 50/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 51/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 52/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 53/65\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 54/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7500\n",
            "Epoch 55/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 56/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 57/65\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 58/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 59/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 60/65\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 61/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 62/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.7500\n",
            "Epoch 63/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 64/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 65/65\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 70 epochs\n",
            "Epoch 1/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 2/70\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 3/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 4/70\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2485 - accuracy: 0.7500\n",
            "Epoch 5/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 6/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 7/70\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 8/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 9/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 10/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 11/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.7500\n",
            "Epoch 12/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 13/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 14/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 15/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 16/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 17/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 18/70\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.7500\n",
            "Epoch 19/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 20/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 21/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 22/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 23/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 24/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.7500\n",
            "Epoch 25/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 26/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 27/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 28/70\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 29/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 30/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2481 - accuracy: 0.7500\n",
            "Epoch 31/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 32/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 33/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 34/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 35/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 36/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.7500\n",
            "Epoch 37/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 38/70\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 39/70\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 40/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 41/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 42/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2479 - accuracy: 0.7500\n",
            "Epoch 43/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 44/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 45/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 46/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 47/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 48/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.7500\n",
            "Epoch 49/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.7500\n",
            "Epoch 50/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.7500\n",
            "Epoch 51/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.7500\n",
            "Epoch 52/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.7500\n",
            "Epoch 53/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.7500\n",
            "Epoch 54/70\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.7500\n",
            "Epoch 55/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2476 - accuracy: 0.7500\n",
            "Epoch 56/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2476 - accuracy: 0.7500\n",
            "Epoch 57/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2476 - accuracy: 0.7500\n",
            "Epoch 58/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2476 - accuracy: 0.7500\n",
            "Epoch 59/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.7500\n",
            "Epoch 60/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.7500\n",
            "Epoch 61/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.7500\n",
            "Epoch 62/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.7500\n",
            "Epoch 63/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.7500\n",
            "Epoch 64/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.7500\n",
            "Epoch 65/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.7500\n",
            "Epoch 66/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.7500\n",
            "Epoch 67/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.7500\n",
            "Epoch 68/70\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2474 - accuracy: 0.7500\n",
            "Epoch 69/70\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "Epoch 70/70\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 75 epochs\n",
            "Epoch 1/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "Epoch 2/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "Epoch 3/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "Epoch 4/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2472 - accuracy: 0.7500\n",
            "Epoch 5/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.7500\n",
            "Epoch 6/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.7500\n",
            "Epoch 7/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.7500\n",
            "Epoch 8/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.7500\n",
            "Epoch 9/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2471 - accuracy: 0.7500\n",
            "Epoch 10/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2471 - accuracy: 0.7500\n",
            "Epoch 11/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2471 - accuracy: 0.7500\n",
            "Epoch 12/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2471 - accuracy: 0.7500\n",
            "Epoch 13/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.7500\n",
            "Epoch 14/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2470 - accuracy: 0.7500\n",
            "Epoch 15/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.7500\n",
            "Epoch 16/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.7500\n",
            "Epoch 17/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.7500\n",
            "Epoch 18/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2469 - accuracy: 0.7500\n",
            "Epoch 19/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2469 - accuracy: 0.7500\n",
            "Epoch 20/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2469 - accuracy: 0.7500\n",
            "Epoch 21/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2469 - accuracy: 0.7500\n",
            "Epoch 22/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2468 - accuracy: 0.7500\n",
            "Epoch 23/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.7500\n",
            "Epoch 24/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.7500\n",
            "Epoch 25/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.7500\n",
            "Epoch 26/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.7500\n",
            "Epoch 27/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.7500\n",
            "Epoch 28/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2467 - accuracy: 0.7500\n",
            "Epoch 29/75\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.7500\n",
            "Epoch 30/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2466 - accuracy: 0.7500\n",
            "Epoch 31/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2466 - accuracy: 0.7500\n",
            "Epoch 32/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2466 - accuracy: 0.7500\n",
            "Epoch 33/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2466 - accuracy: 0.7500\n",
            "Epoch 34/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2466 - accuracy: 0.7500\n",
            "Epoch 35/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2465 - accuracy: 0.7500\n",
            "Epoch 36/75\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2465 - accuracy: 0.7500\n",
            "Epoch 37/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2465 - accuracy: 0.7500\n",
            "Epoch 38/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.7500\n",
            "Epoch 39/75\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2464 - accuracy: 0.7500\n",
            "Epoch 40/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2464 - accuracy: 0.7500\n",
            "Epoch 41/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2464 - accuracy: 0.7500\n",
            "Epoch 42/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2464 - accuracy: 0.7500\n",
            "Epoch 43/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2463 - accuracy: 0.7500\n",
            "Epoch 44/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2463 - accuracy: 0.7500\n",
            "Epoch 45/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2463 - accuracy: 0.7500\n",
            "Epoch 46/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.7500\n",
            "Epoch 47/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2462 - accuracy: 0.7500\n",
            "Epoch 48/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.7500\n",
            "Epoch 49/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2462 - accuracy: 0.7500\n",
            "Epoch 50/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.7500\n",
            "Epoch 51/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2461 - accuracy: 0.7500\n",
            "Epoch 52/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.7500\n",
            "Epoch 53/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.7500\n",
            "Epoch 54/75\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2460 - accuracy: 0.7500\n",
            "Epoch 55/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2460 - accuracy: 0.7500\n",
            "Epoch 56/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2460 - accuracy: 0.7500\n",
            "Epoch 57/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2460 - accuracy: 0.7500\n",
            "Epoch 58/75\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2459 - accuracy: 0.7500\n",
            "Epoch 59/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.7500\n",
            "Epoch 60/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2459 - accuracy: 0.7500\n",
            "Epoch 61/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2458 - accuracy: 0.7500\n",
            "Epoch 62/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2458 - accuracy: 0.7500\n",
            "Epoch 63/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2458 - accuracy: 0.7500\n",
            "Epoch 64/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2458 - accuracy: 0.7500\n",
            "Epoch 65/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.7500\n",
            "Epoch 66/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.7500\n",
            "Epoch 67/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.7500\n",
            "Epoch 68/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.7500\n",
            "Epoch 69/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2456 - accuracy: 0.7500\n",
            "Epoch 70/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.7500\n",
            "Epoch 71/75\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.7500\n",
            "Epoch 72/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.7500\n",
            "Epoch 73/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.7500\n",
            "Epoch 74/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.7500\n",
            "Epoch 75/75\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2454 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 80 epochs\n",
            "Epoch 1/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2454 - accuracy: 0.7500\n",
            "Epoch 2/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2454 - accuracy: 0.7500\n",
            "Epoch 3/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2454 - accuracy: 0.7500\n",
            "Epoch 4/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.7500\n",
            "Epoch 5/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.7500\n",
            "Epoch 6/80\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2453 - accuracy: 0.7500\n",
            "Epoch 7/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2452 - accuracy: 0.7500\n",
            "Epoch 8/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2452 - accuracy: 0.7500\n",
            "Epoch 9/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2452 - accuracy: 0.7500\n",
            "Epoch 10/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2452 - accuracy: 0.7500\n",
            "Epoch 11/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2451 - accuracy: 0.7500\n",
            "Epoch 12/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2451 - accuracy: 0.7500\n",
            "Epoch 13/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2451 - accuracy: 0.7500\n",
            "Epoch 14/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2450 - accuracy: 0.7500\n",
            "Epoch 15/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2450 - accuracy: 0.7500\n",
            "Epoch 16/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2450 - accuracy: 0.7500\n",
            "Epoch 17/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.7500\n",
            "Epoch 18/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.7500\n",
            "Epoch 19/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.7500\n",
            "Epoch 20/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2448 - accuracy: 0.7500\n",
            "Epoch 21/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2448 - accuracy: 0.7500\n",
            "Epoch 22/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2448 - accuracy: 0.7500\n",
            "Epoch 23/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2448 - accuracy: 0.7500\n",
            "Epoch 24/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2447 - accuracy: 0.7500\n",
            "Epoch 25/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.7500\n",
            "Epoch 26/80\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2447 - accuracy: 0.7500\n",
            "Epoch 27/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2446 - accuracy: 0.7500\n",
            "Epoch 28/80\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2446 - accuracy: 0.7500\n",
            "Epoch 29/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.7500\n",
            "Epoch 30/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2445 - accuracy: 0.7500\n",
            "Epoch 31/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2445 - accuracy: 0.7500\n",
            "Epoch 32/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2445 - accuracy: 0.7500\n",
            "Epoch 33/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2444 - accuracy: 0.7500\n",
            "Epoch 34/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2444 - accuracy: 0.7500\n",
            "Epoch 35/80\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2444 - accuracy: 0.7500\n",
            "Epoch 36/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.7500\n",
            "Epoch 37/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2443 - accuracy: 0.7500\n",
            "Epoch 38/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.7500\n",
            "Epoch 39/80\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2442 - accuracy: 0.7500\n",
            "Epoch 40/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2442 - accuracy: 0.7500\n",
            "Epoch 41/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2442 - accuracy: 0.7500\n",
            "Epoch 42/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2441 - accuracy: 0.7500\n",
            "Epoch 43/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2441 - accuracy: 0.7500\n",
            "Epoch 44/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2441 - accuracy: 0.7500\n",
            "Epoch 45/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2440 - accuracy: 0.7500\n",
            "Epoch 46/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2440 - accuracy: 0.7500\n",
            "Epoch 47/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.7500\n",
            "Epoch 48/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2439 - accuracy: 0.7500\n",
            "Epoch 49/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2439 - accuracy: 0.7500\n",
            "Epoch 50/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2439 - accuracy: 0.7500\n",
            "Epoch 51/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.7500\n",
            "Epoch 52/80\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2438 - accuracy: 0.7500\n",
            "Epoch 53/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2438 - accuracy: 0.7500\n",
            "Epoch 54/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2437 - accuracy: 0.7500\n",
            "Epoch 55/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.7500\n",
            "Epoch 56/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.7500\n",
            "Epoch 57/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2436 - accuracy: 0.7500\n",
            "Epoch 58/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2436 - accuracy: 0.7500\n",
            "Epoch 59/80\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2435 - accuracy: 0.7500\n",
            "Epoch 60/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2435 - accuracy: 0.7500\n",
            "Epoch 61/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2435 - accuracy: 0.7500\n",
            "Epoch 62/80\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2434 - accuracy: 0.7500\n",
            "Epoch 63/80\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2434 - accuracy: 0.7500\n",
            "Epoch 64/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.7500\n",
            "Epoch 65/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2433 - accuracy: 0.7500\n",
            "Epoch 66/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2433 - accuracy: 0.7500\n",
            "Epoch 67/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2433 - accuracy: 0.7500\n",
            "Epoch 68/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2432 - accuracy: 0.7500\n",
            "Epoch 69/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2432 - accuracy: 0.7500\n",
            "Epoch 70/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2431 - accuracy: 0.7500\n",
            "Epoch 71/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2431 - accuracy: 0.7500\n",
            "Epoch 72/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2431 - accuracy: 0.7500\n",
            "Epoch 73/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2430 - accuracy: 0.7500\n",
            "Epoch 74/80\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2430 - accuracy: 0.7500\n",
            "Epoch 75/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2430 - accuracy: 0.7500\n",
            "Epoch 76/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.7500\n",
            "Epoch 77/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.7500\n",
            "Epoch 78/80\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2428 - accuracy: 0.7500\n",
            "Epoch 79/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.7500\n",
            "Epoch 80/80\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2427 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 85 epochs\n",
            "Epoch 1/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2427 - accuracy: 0.7500\n",
            "Epoch 2/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2427 - accuracy: 0.7500\n",
            "Epoch 3/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2427 - accuracy: 0.7500\n",
            "Epoch 4/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.7500\n",
            "Epoch 5/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.7500\n",
            "Epoch 6/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.7500\n",
            "Epoch 7/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.7500\n",
            "Epoch 8/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.7500\n",
            "Epoch 9/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2424 - accuracy: 0.7500\n",
            "Epoch 10/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2424 - accuracy: 0.7500\n",
            "Epoch 11/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.7500\n",
            "Epoch 12/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2423 - accuracy: 0.7500\n",
            "Epoch 13/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2423 - accuracy: 0.7500\n",
            "Epoch 14/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2422 - accuracy: 0.7500\n",
            "Epoch 15/85\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2422 - accuracy: 0.7500\n",
            "Epoch 16/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2422 - accuracy: 0.7500\n",
            "Epoch 17/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.7500\n",
            "Epoch 18/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.7500\n",
            "Epoch 19/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2420 - accuracy: 0.7500\n",
            "Epoch 20/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2420 - accuracy: 0.7500\n",
            "Epoch 21/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2420 - accuracy: 0.7500\n",
            "Epoch 22/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2419 - accuracy: 0.7500\n",
            "Epoch 23/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2419 - accuracy: 0.7500\n",
            "Epoch 24/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2418 - accuracy: 0.7500\n",
            "Epoch 25/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2418 - accuracy: 0.7500\n",
            "Epoch 26/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2417 - accuracy: 0.7500\n",
            "Epoch 27/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.7500\n",
            "Epoch 28/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2417 - accuracy: 0.7500\n",
            "Epoch 29/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2416 - accuracy: 0.7500\n",
            "Epoch 30/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2416 - accuracy: 0.7500\n",
            "Epoch 31/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2415 - accuracy: 0.7500\n",
            "Epoch 32/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.7500\n",
            "Epoch 33/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.7500\n",
            "Epoch 34/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2414 - accuracy: 0.7500\n",
            "Epoch 35/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2414 - accuracy: 0.7500\n",
            "Epoch 36/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.7500\n",
            "Epoch 37/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.7500\n",
            "Epoch 38/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2412 - accuracy: 0.7500\n",
            "Epoch 39/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.7500\n",
            "Epoch 40/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.7500\n",
            "Epoch 41/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.7500\n",
            "Epoch 42/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.7500\n",
            "Epoch 43/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2410 - accuracy: 0.7500\n",
            "Epoch 44/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2410 - accuracy: 0.7500\n",
            "Epoch 45/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2409 - accuracy: 0.7500\n",
            "Epoch 46/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.7500\n",
            "Epoch 47/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2409 - accuracy: 0.7500\n",
            "Epoch 48/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2408 - accuracy: 0.7500\n",
            "Epoch 49/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2408 - accuracy: 0.7500\n",
            "Epoch 50/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2407 - accuracy: 0.7500\n",
            "Epoch 51/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.7500\n",
            "Epoch 52/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.7500\n",
            "Epoch 53/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.7500\n",
            "Epoch 54/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2406 - accuracy: 0.7500\n",
            "Epoch 55/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2405 - accuracy: 0.7500\n",
            "Epoch 56/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2405 - accuracy: 0.7500\n",
            "Epoch 57/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2404 - accuracy: 0.7500\n",
            "Epoch 58/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.7500\n",
            "Epoch 59/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2403 - accuracy: 0.7500\n",
            "Epoch 60/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2403 - accuracy: 0.7500\n",
            "Epoch 61/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.7500\n",
            "Epoch 62/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2402 - accuracy: 0.7500\n",
            "Epoch 63/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2402 - accuracy: 0.7500\n",
            "Epoch 64/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2401 - accuracy: 0.7500\n",
            "Epoch 65/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 0.7500\n",
            "Epoch 66/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2400 - accuracy: 0.7500\n",
            "Epoch 67/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.7500\n",
            "Epoch 68/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.7500\n",
            "Epoch 69/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.7500\n",
            "Epoch 70/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2398 - accuracy: 0.7500\n",
            "Epoch 71/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2398 - accuracy: 0.7500\n",
            "Epoch 72/85\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2397 - accuracy: 0.7500\n",
            "Epoch 73/85\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.7500\n",
            "Epoch 74/85\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2396 - accuracy: 0.7500\n",
            "Epoch 75/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2396 - accuracy: 0.7500\n",
            "Epoch 76/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2396 - accuracy: 0.7500\n",
            "Epoch 77/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2395 - accuracy: 0.7500\n",
            "Epoch 78/85\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2395 - accuracy: 0.7500\n",
            "Epoch 79/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2394 - accuracy: 0.7500\n",
            "Epoch 80/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2394 - accuracy: 0.7500\n",
            "Epoch 81/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.7500\n",
            "Epoch 82/85\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.7500\n",
            "Epoch 83/85\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2392 - accuracy: 0.7500\n",
            "Epoch 84/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2392 - accuracy: 0.7500\n",
            "Epoch 85/85\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2391 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2391 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 90 epochs\n",
            "Epoch 1/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.7500\n",
            "Epoch 2/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2390 - accuracy: 0.7500\n",
            "Epoch 3/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2390 - accuracy: 0.7500\n",
            "Epoch 4/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2389 - accuracy: 0.7500\n",
            "Epoch 5/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2389 - accuracy: 0.7500\n",
            "Epoch 6/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2388 - accuracy: 0.7500\n",
            "Epoch 7/90\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2388 - accuracy: 0.7500\n",
            "Epoch 8/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2387 - accuracy: 0.7500\n",
            "Epoch 9/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2387 - accuracy: 0.7500\n",
            "Epoch 10/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2386 - accuracy: 0.7500\n",
            "Epoch 11/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2386 - accuracy: 0.7500\n",
            "Epoch 12/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2385 - accuracy: 0.7500\n",
            "Epoch 13/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2385 - accuracy: 0.7500\n",
            "Epoch 14/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2384 - accuracy: 0.7500\n",
            "Epoch 15/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2384 - accuracy: 0.7500\n",
            "Epoch 16/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.7500\n",
            "Epoch 17/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.7500\n",
            "Epoch 18/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2382 - accuracy: 0.7500\n",
            "Epoch 19/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2382 - accuracy: 0.7500\n",
            "Epoch 20/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2381 - accuracy: 0.7500\n",
            "Epoch 21/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2381 - accuracy: 0.7500\n",
            "Epoch 22/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.7500\n",
            "Epoch 23/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.7500\n",
            "Epoch 24/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2379 - accuracy: 0.7500\n",
            "Epoch 25/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2379 - accuracy: 0.7500\n",
            "Epoch 26/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2378 - accuracy: 0.7500\n",
            "Epoch 27/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2378 - accuracy: 0.7500\n",
            "Epoch 28/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2377 - accuracy: 0.7500\n",
            "Epoch 29/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2377 - accuracy: 0.7500\n",
            "Epoch 30/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.7500\n",
            "Epoch 31/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2376 - accuracy: 0.7500\n",
            "Epoch 32/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.7500\n",
            "Epoch 33/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.7500\n",
            "Epoch 34/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.7500\n",
            "Epoch 35/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2374 - accuracy: 0.7500\n",
            "Epoch 36/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2373 - accuracy: 0.7500\n",
            "Epoch 37/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2373 - accuracy: 0.7500\n",
            "Epoch 38/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2372 - accuracy: 0.7500\n",
            "Epoch 39/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2372 - accuracy: 0.7500\n",
            "Epoch 40/90\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.7500\n",
            "Epoch 41/90\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.7500\n",
            "Epoch 42/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2370 - accuracy: 0.7500\n",
            "Epoch 43/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.7500\n",
            "Epoch 44/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2369 - accuracy: 0.7500\n",
            "Epoch 45/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2368 - accuracy: 0.7500\n",
            "Epoch 46/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2368 - accuracy: 0.7500\n",
            "Epoch 47/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2367 - accuracy: 0.7500\n",
            "Epoch 48/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2367 - accuracy: 0.7500\n",
            "Epoch 49/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2366 - accuracy: 0.7500\n",
            "Epoch 50/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.7500\n",
            "Epoch 51/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2365 - accuracy: 0.7500\n",
            "Epoch 52/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.7500\n",
            "Epoch 53/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.7500\n",
            "Epoch 54/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2364 - accuracy: 0.7500\n",
            "Epoch 55/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2363 - accuracy: 0.7500\n",
            "Epoch 56/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2363 - accuracy: 0.7500\n",
            "Epoch 57/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2362 - accuracy: 0.7500\n",
            "Epoch 58/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.7500\n",
            "Epoch 59/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.7500\n",
            "Epoch 60/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2360 - accuracy: 0.7500\n",
            "Epoch 61/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2360 - accuracy: 0.7500\n",
            "Epoch 62/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2359 - accuracy: 0.7500\n",
            "Epoch 63/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2359 - accuracy: 0.7500\n",
            "Epoch 64/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2358 - accuracy: 0.7500\n",
            "Epoch 65/90\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2358 - accuracy: 0.7500\n",
            "Epoch 66/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.7500\n",
            "Epoch 67/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2356 - accuracy: 0.7500\n",
            "Epoch 68/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2356 - accuracy: 0.7500\n",
            "Epoch 69/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2355 - accuracy: 0.7500\n",
            "Epoch 70/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2355 - accuracy: 0.7500\n",
            "Epoch 71/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2354 - accuracy: 0.7500\n",
            "Epoch 72/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2354 - accuracy: 0.7500\n",
            "Epoch 73/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2353 - accuracy: 0.7500\n",
            "Epoch 74/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2353 - accuracy: 0.7500\n",
            "Epoch 75/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2352 - accuracy: 0.7500\n",
            "Epoch 76/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 0.7500\n",
            "Epoch 77/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2351 - accuracy: 0.7500\n",
            "Epoch 78/90\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2350 - accuracy: 0.7500\n",
            "Epoch 79/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2350 - accuracy: 0.7500\n",
            "Epoch 80/90\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2349 - accuracy: 0.7500\n",
            "Epoch 81/90\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2348 - accuracy: 0.7500\n",
            "Epoch 82/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2348 - accuracy: 0.7500\n",
            "Epoch 83/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.7500\n",
            "Epoch 84/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.7500\n",
            "Epoch 85/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.7500\n",
            "Epoch 86/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2346 - accuracy: 0.7500\n",
            "Epoch 87/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2345 - accuracy: 0.7500\n",
            "Epoch 88/90\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2344 - accuracy: 0.7500\n",
            "Epoch 89/90\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2344 - accuracy: 0.7500\n",
            "Epoch 90/90\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2343 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2343 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 95 epochs\n",
            "Epoch 1/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2343 - accuracy: 0.7500\n",
            "Epoch 2/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2342 - accuracy: 0.7500\n",
            "Epoch 3/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2341 - accuracy: 0.7500\n",
            "Epoch 4/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2341 - accuracy: 0.7500\n",
            "Epoch 5/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2340 - accuracy: 0.7500\n",
            "Epoch 6/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2340 - accuracy: 0.7500\n",
            "Epoch 7/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2339 - accuracy: 0.7500\n",
            "Epoch 8/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2339 - accuracy: 0.7500\n",
            "Epoch 9/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2338 - accuracy: 0.7500\n",
            "Epoch 10/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2337 - accuracy: 0.7500\n",
            "Epoch 11/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2337 - accuracy: 0.7500\n",
            "Epoch 12/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2336 - accuracy: 0.7500\n",
            "Epoch 13/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2336 - accuracy: 0.7500\n",
            "Epoch 14/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.7500\n",
            "Epoch 15/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.7500\n",
            "Epoch 16/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2334 - accuracy: 0.7500\n",
            "Epoch 17/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.7500\n",
            "Epoch 18/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2332 - accuracy: 0.7500\n",
            "Epoch 19/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2332 - accuracy: 0.7500\n",
            "Epoch 20/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2331 - accuracy: 0.7500\n",
            "Epoch 21/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2331 - accuracy: 0.7500\n",
            "Epoch 22/95\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2330 - accuracy: 0.7500\n",
            "Epoch 23/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.7500\n",
            "Epoch 24/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2329 - accuracy: 0.7500\n",
            "Epoch 25/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2328 - accuracy: 0.7500\n",
            "Epoch 26/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2328 - accuracy: 0.7500\n",
            "Epoch 27/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2327 - accuracy: 0.7500\n",
            "Epoch 28/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2326 - accuracy: 0.7500\n",
            "Epoch 29/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2326 - accuracy: 0.7500\n",
            "Epoch 30/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.7500\n",
            "Epoch 31/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2324 - accuracy: 0.7500\n",
            "Epoch 32/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2324 - accuracy: 0.7500\n",
            "Epoch 33/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.7500\n",
            "Epoch 34/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2323 - accuracy: 0.7500\n",
            "Epoch 35/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2322 - accuracy: 0.7500\n",
            "Epoch 36/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2321 - accuracy: 0.7500\n",
            "Epoch 37/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2321 - accuracy: 0.7500\n",
            "Epoch 38/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.7500\n",
            "Epoch 39/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.7500\n",
            "Epoch 40/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.7500\n",
            "Epoch 41/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2318 - accuracy: 0.7500\n",
            "Epoch 42/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2318 - accuracy: 0.7500\n",
            "Epoch 43/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2317 - accuracy: 0.7500\n",
            "Epoch 44/95\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2316 - accuracy: 0.7500\n",
            "Epoch 45/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2316 - accuracy: 0.7500\n",
            "Epoch 46/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2315 - accuracy: 0.7500\n",
            "Epoch 47/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2314 - accuracy: 0.7500\n",
            "Epoch 48/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2314 - accuracy: 0.7500\n",
            "Epoch 49/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2313 - accuracy: 0.7500\n",
            "Epoch 50/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2312 - accuracy: 0.7500\n",
            "Epoch 51/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2312 - accuracy: 0.7500\n",
            "Epoch 52/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 0.7500\n",
            "Epoch 53/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2310 - accuracy: 0.7500\n",
            "Epoch 54/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2310 - accuracy: 0.7500\n",
            "Epoch 55/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2309 - accuracy: 0.7500\n",
            "Epoch 56/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 0.7500\n",
            "Epoch 57/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.7500\n",
            "Epoch 58/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2307 - accuracy: 0.7500\n",
            "Epoch 59/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2307 - accuracy: 0.7500\n",
            "Epoch 60/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2306 - accuracy: 0.7500\n",
            "Epoch 61/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 0.7500\n",
            "Epoch 62/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2305 - accuracy: 0.7500\n",
            "Epoch 63/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2304 - accuracy: 0.7500\n",
            "Epoch 64/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2303 - accuracy: 0.7500\n",
            "Epoch 65/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 0.7500\n",
            "Epoch 66/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2302 - accuracy: 0.7500\n",
            "Epoch 67/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2301 - accuracy: 0.7500\n",
            "Epoch 68/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2301 - accuracy: 0.7500\n",
            "Epoch 69/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2300 - accuracy: 0.7500\n",
            "Epoch 70/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2299 - accuracy: 0.7500\n",
            "Epoch 71/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2299 - accuracy: 0.7500\n",
            "Epoch 72/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2298 - accuracy: 0.7500\n",
            "Epoch 73/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2297 - accuracy: 0.7500\n",
            "Epoch 74/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2297 - accuracy: 0.7500\n",
            "Epoch 75/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2296 - accuracy: 0.7500\n",
            "Epoch 76/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2295 - accuracy: 0.7500\n",
            "Epoch 77/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2295 - accuracy: 0.7500\n",
            "Epoch 78/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.7500\n",
            "Epoch 79/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2293 - accuracy: 0.7500\n",
            "Epoch 80/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2292 - accuracy: 0.7500\n",
            "Epoch 81/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2292 - accuracy: 0.7500\n",
            "Epoch 82/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2291 - accuracy: 0.7500\n",
            "Epoch 83/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 0.7500\n",
            "Epoch 84/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2290 - accuracy: 0.7500\n",
            "Epoch 85/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2289 - accuracy: 0.7500\n",
            "Epoch 86/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2288 - accuracy: 0.7500\n",
            "Epoch 87/95\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2288 - accuracy: 0.7500\n",
            "Epoch 88/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.7500\n",
            "Epoch 89/95\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2286 - accuracy: 0.7500\n",
            "Epoch 90/95\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2286 - accuracy: 0.7500\n",
            "Epoch 91/95\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.7500\n",
            "Epoch 92/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2284 - accuracy: 0.7500\n",
            "Epoch 93/95\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2284 - accuracy: 0.7500\n",
            "Epoch 94/95\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2283 - accuracy: 0.7500\n",
            "Epoch 95/95\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2282 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2281 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "=====================================================================\n",
            "Para el modelo 8潞 con 100 epochs\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2281 - accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2281 - accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2280 - accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2279 - accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2279 - accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2278 - accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2277 - accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2277 - accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2276 - accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2275 - accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2274 - accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2274 - accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2273 - accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2272 - accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2272 - accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2271 - accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2270 - accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2269 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2269 - accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2267 - accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2266 - accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2266 - accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2263 - accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2262 - accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2261 - accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2261 - accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2260 - accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2259 - accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2258 - accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2258 - accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2256 - accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2256 - accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2254 - accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2253 - accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2253 - accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2252 - accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2251 - accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2250 - accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2250 - accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2249 - accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2248 - accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2247 - accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2247 - accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2246 - accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2245 - accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2244 - accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2244 - accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2242 - accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2240 - accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2240 - accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2239 - accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2238 - accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2237 - accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2237 - accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2236 - accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2235 - accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2234 - accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2234 - accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2232 - accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2231 - accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2230 - accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2230 - accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2228 - accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2227 - accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2227 - accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2226 - accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2224 - accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2223 - accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2223 - accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2222 - accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2221 - accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2219 - accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2217 - accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2216 - accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2215 - accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2214 - accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2213 - accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2212 - accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2209 - accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2206 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2206 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "=====================================================================\n"
          ]
        }
      ],
      "source": [
        "# Preparo para guardar los modelos\n",
        "# Guardo el entrenamiento\n",
        "m_tr = []\n",
        "# Guardo la evaluaci贸n\n",
        "m_ev = []\n",
        "# Guardo las predicciones\n",
        "m_pr = []\n",
        "# Entrenamos los modelos para todos los modelos creados y para todas las iteraciones planteadas\n",
        "for i in range(0, len(modelos_MLP)):\n",
        "        for j in range(0, len(iters)):\n",
        "            # Mostramos el progreso del modelo\n",
        "            print('Para el modelo ' + str(i+1) + '潞 con ' + str(iters[j]) + ' epochs')\n",
        "            m_tr.append(modelos_MLP[i].fit(x=entradas, y=salidas, batch_size=entradas.shape[0], epochs=iters[j])) # Entrenamos\n",
        "            m_ev.append(modelos_MLP[i].evaluate(x=entradas, y=salidas, batch_size=entradas.shape[0])) # Evaluamos\n",
        "            m_pr.append(modelos_MLP[i].predict(x=entradas, batch_size=entradas.shape[0])) # Predecimos\n",
        "            print('=====================================================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7XH0EpQsbJz-"
      },
      "id": "7XH0EpQsbJz-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos la evaluaci贸n en las 2 categor铆as que analizamos (error y precisi贸n)\n",
        "m_loss, m_acc = zip(*m_ev)\n",
        "\n",
        "# Encontramos el error m谩s baj0\n",
        "min_loss = m_loss.index(min(m_loss))\n",
        "print('Menor error [' + str(min_loss) + ']: ' + str(m_loss[min_loss]))\n",
        "print(m_pr[min_loss])\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[min_loss].history['accuracy'])\n",
        "plt.title('Precisi贸n')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[min_loss].history['loss'])\n",
        "plt.title('Error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "print('\\nModelo con la mayor precisi贸n\\n')\n",
        "modelos_MLP[min_loss%len(modelos_MLP)].summary()\n",
        "print('\\n')\n",
        "\n",
        "display(SVG(model_to_dot(\n",
        "    modelos_MLP[min_loss%len(modelos_MLP)],\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True,\n",
        "    show_layer_activations=True).create(prog='dot', format='svg')))\n",
        "print('=========================')\n",
        "print('=========================')\n",
        "\n",
        "# Encontramos la precisi贸n m谩s alta\n",
        "max_acc = m_acc.index(max(m_acc))\n",
        "print('Mayor precisi贸n [' + str(max_acc) + ']: ' + str(m_acc[max_acc]))\n",
        "print(m_pr[max_acc])\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[max_acc].history['accuracy'])\n",
        "plt.title('Precisi贸n')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[max_acc].history['loss'])\n",
        "plt.title('Error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "print('\\nModelo con el error m铆nimo\\n')\n",
        "modelos_MLP[max_acc%len(modelos_MLP)].summary()\n",
        "print('\\n')\n",
        "\n",
        "display(SVG(model_to_dot(\n",
        "    modelos_MLP[max_acc%len(modelos_MLP)],\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True,\n",
        "    show_layer_activations=True).create(prog='dot', format='svg')))\n",
        "print('=========================')\n",
        "print('=========================')\n",
        "\n",
        "\n",
        "# Para encontrar las salidas m谩s parecidas a las esperadas realizamos la\n",
        "# raiz cuadrada del sumatorio de la diferencia de cuadrados normalizada\n",
        "m_pr = np.asarray(m_pr)\n",
        "similares = np.sqrt(np.sum((m_pr / m_pr.sum(axis=1)[:, np.newaxis] - salidas / np.sum(salidas))**2, axis=1))\n",
        "# Eliminiar NaN (obtenidos por divisiones entre 0) mediante hacerlos m谩s grandes\n",
        "# que 1 elemento\n",
        "similares[np.isnan(similares)] = 1\n",
        "result = m_pr[similares.argmin()]\n",
        "# Conseguimos el index del patron m谩s parecido\n",
        "idx_result = int(np.argwhere(np.all(m_pr==result, axis=(1,2))))\n",
        "print('Patron m谩s parecido [' + str(idx_result) + ']')\n",
        "print(result)\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[idx_result].history['accuracy'])\n",
        "plt.title('Precisi贸n')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "plt.plot(m_tr[idx_result].history['loss'])\n",
        "plt.title('Error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "print('\\n=========================')\n",
        "print('\\nModelo con la predicci贸n m谩s parecida\\n')\n",
        "modelos_MLP[idx_result%len(modelos_MLP)].summary()\n",
        "print('\\n')\n",
        "\n",
        "display(SVG(model_to_dot(\n",
        "    modelos_MLP[idx_result%len(modelos_MLP)],\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True,\n",
        "    show_layer_activations=True).create(prog='dot', format='svg')))\n",
        "print('=========================')\n",
        "print('=========================')\n",
        "\n",
        "# Guardamos los datos del entrenamiento en la siguiente tabla\n",
        "N = np.zeros(len(m_pr))\n",
        "for i in range(0, len(m_pr)):\n",
        "  if i < 80:\n",
        "    N[i] = 2\n",
        "  else:\n",
        "    N[i] = 3\n",
        "\n",
        "I = np.zeros(len(m_pr))\n",
        "for j in range(0, len(modelos_MLP)):\n",
        "  for k in range(0, len(iters)):\n",
        "    I[(j*len(iters))+k] = iters[k]\n",
        "\n",
        "neuronas = []\n",
        "for j in range(0, len(modelos_MLP)):\n",
        "  for k in range(0, len(iters)):\n",
        "    current = []\n",
        "    conf_act = j%4\n",
        "    if conf_act == 0:\n",
        "      current.append('relu')\n",
        "      current.append('relu')\n",
        "    elif conf_act == 1:\n",
        "      current.append('relu')\n",
        "      current.append('sigmoid')\n",
        "    elif conf_act == 2:\n",
        "      current.append('sigmoid')\n",
        "      current.append('relu')\n",
        "    else:\n",
        "      current.append('sigmoid')\n",
        "      current.append('sigmoid')\n",
        "    neuronas.append(current)\n",
        "\n",
        "col1 = pd.Series(I.tolist())\n",
        "col2 = pd.Series(N.tolist())\n",
        "col3 = pd.Series(m_pr.tolist())\n",
        "col4 = pd.Series(list(m_loss))\n",
        "d = {'Iteraciones': col1, 'Neuronas': col2, 'Salida': col3, 'Error': col4, 'Configuraci贸n': neuronas}\n",
        "df = pd.DataFrame(d)\n",
        "pd.set_option('display.max_rows', df.shape[0]+1)\n",
        "df.to_csv(\"L2P2-XOR_Multicapa.csv\", index = False)\n",
        "df"
      ],
      "metadata": {
        "id": "CrOMP129fvte",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4da06c5-0e68-4a81-e47b-ed196db1b650"
      },
      "id": "CrOMP129fvte",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menor error [119]: 0.01694938912987709\n",
            "[[0.15503494]\n",
            " [0.9206464 ]\n",
            " [0.8841169 ]\n",
            " [0.15503494]]\n",
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n",
            "\n",
            "Modelo con la mayor precisi贸n\n",
            "\n",
            "Model: \"3nHsigmoidOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"324pt\" height=\"295pt\" viewBox=\"0.00 0.00 243.00 221.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-217 239,-217 239,4 -4,4\"/>\n<!-- 139857460283664 -->\n<g id=\"node1\" class=\"node\">\n<title>139857460283664</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"9.5,-166.5 9.5,-212.5 225.5,-212.5 225.5,-166.5 9.5,-166.5\"/>\n<text text-anchor=\"middle\" x=\"51\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"9.5,-189.5 92.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"51\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"92.5,-166.5 92.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"120\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"92.5,-189.5 147.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"120\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-166.5 147.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-189.5 225.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n</g>\n<!-- 139857460314064 -->\n<g id=\"node2\" class=\"node\">\n<title>139857460314064</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-83.5 0,-129.5 235,-129.5 235,-83.5 0,-83.5\"/>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">Hidden_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-106.5 111,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"25\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"50,-83.5 50,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-83.5 111,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-106.5 166,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-83.5 166,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-106.5 235,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 3)</text>\n</g>\n<!-- 139857460283664&#45;&gt;139857460314064 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139857460283664-&gt;139857460314064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.5,-166.37C117.5,-158.15 117.5,-148.66 117.5,-139.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121,-139.61 117.5,-129.61 114,-139.61 121,-139.61\"/>\n</g>\n<!-- 139857460326464 -->\n<g id=\"node3\" class=\"node\">\n<title>139857460326464</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-46.5 235,-46.5 235,-0.5 0,-0.5\"/>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Output_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 111,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"25\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"50,-0.5 50,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-0.5 111,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-23.5 166,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-0.5 166,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 3)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-23.5 235,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n</g>\n<!-- 139857460314064&#45;&gt;139857460326464 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139857460314064-&gt;139857460326464</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.5,-83.37C117.5,-75.15 117.5,-65.66 117.5,-56.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121,-56.61 117.5,-46.61 114,-56.61 121,-56.61\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "=========================\n",
            "Mayor precisi贸n [104]: 1.0\n",
            "[[0.41992724]\n",
            " [0.7805375 ]\n",
            " [0.5023544 ]\n",
            " [0.43202   ]]\n",
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n",
            "\n",
            "Modelo con el error m铆nimo\n",
            "\n",
            "Model: \"2nHreluOrelu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 2)                 6         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"303pt\" height=\"295pt\" viewBox=\"0.00 0.00 227.00 221.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-217 223,-217 223,4 -4,4\"/>\n<!-- 139859751277712 -->\n<g id=\"node1\" class=\"node\">\n<title>139859751277712</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1.5,-166.5 1.5,-212.5 217.5,-212.5 217.5,-166.5 1.5,-166.5\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1.5,-189.5 84.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"84.5,-166.5 84.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"112\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"84.5,-189.5 139.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"112\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-166.5 139.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"178.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-189.5 217.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"178.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n</g>\n<!-- 139857542658896 -->\n<g id=\"node2\" class=\"node\">\n<title>139857542658896</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-83.5 0,-129.5 219,-129.5 219,-83.5 0,-83.5\"/>\n<text text-anchor=\"middle\" x=\"47.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">Hidden_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-106.5 95,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"26.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"53,-83.5 53,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"74\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"95,-83.5 95,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"95,-106.5 150,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"150,-83.5 150,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"150,-106.5 219,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"184.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n</g>\n<!-- 139859751277712&#45;&gt;139857542658896 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139859751277712-&gt;139857542658896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109.5,-166.37C109.5,-158.15 109.5,-148.66 109.5,-139.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"113,-139.61 109.5,-129.61 106,-139.61 113,-139.61\"/>\n</g>\n<!-- 139857542656256 -->\n<g id=\"node3\" class=\"node\">\n<title>139857542656256</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1.5,-0.5 1.5,-46.5 217.5,-46.5 217.5,-0.5 1.5,-0.5\"/>\n<text text-anchor=\"middle\" x=\"47.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Output_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1.5,-23.5 93.5,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"27.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"53.5,-0.5 53.5,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"93.5,-0.5 93.5,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"93.5,-23.5 148.5,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-0.5 148.5,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"148.5,-23.5 217.5,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n</g>\n<!-- 139857542658896&#45;&gt;139857542656256 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139857542658896-&gt;139857542656256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109.5,-83.37C109.5,-75.15 109.5,-65.66 109.5,-56.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"113,-56.61 109.5,-46.61 106,-56.61 113,-56.61\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "=========================\n",
            "Patron m谩s parecido [119]\n",
            "[[0.15503494]\n",
            " [0.9206464 ]\n",
            " [0.8841169 ]\n",
            " [0.15503494]]\n",
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================\n",
            "\n",
            "Modelo con la predicci贸n m谩s parecida\n",
            "\n",
            "Model: \"3nHsigmoidOsigmoid\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"324pt\" height=\"295pt\" viewBox=\"0.00 0.00 243.00 221.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-217 239,-217 239,4 -4,4\"/>\n<!-- 139857460283664 -->\n<g id=\"node1\" class=\"node\">\n<title>139857460283664</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"9.5,-166.5 9.5,-212.5 225.5,-212.5 225.5,-166.5 9.5,-166.5\"/>\n<text text-anchor=\"middle\" x=\"51\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"9.5,-189.5 92.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"51\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"92.5,-166.5 92.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"120\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"92.5,-189.5 147.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"120\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-166.5 147.5,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"147.5,-189.5 225.5,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2)]</text>\n</g>\n<!-- 139857460314064 -->\n<g id=\"node2\" class=\"node\">\n<title>139857460314064</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-83.5 0,-129.5 235,-129.5 235,-83.5 0,-83.5\"/>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">Hidden_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-106.5 111,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"25\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"50,-83.5 50,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-83.5 111,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-106.5 166,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-83.5 166,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-106.5 235,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 3)</text>\n</g>\n<!-- 139857460283664&#45;&gt;139857460314064 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139857460283664-&gt;139857460314064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.5,-166.37C117.5,-158.15 117.5,-148.66 117.5,-139.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121,-139.61 117.5,-129.61 114,-139.61 121,-139.61\"/>\n</g>\n<!-- 139857460326464 -->\n<g id=\"node3\" class=\"node\">\n<title>139857460326464</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-46.5 235,-46.5 235,-0.5 0,-0.5\"/>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Output_Layer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 111,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"25\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"50,-0.5 50,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-0.5 111,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"111,-23.5 166,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"138.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-0.5 166,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 3)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"166,-23.5 235,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n</g>\n<!-- 139857460314064&#45;&gt;139857460326464 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139857460314064-&gt;139857460326464</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.5,-83.37C117.5,-75.15 117.5,-65.66 117.5,-56.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121,-56.61 117.5,-46.61 114,-56.61 121,-56.61\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Iteraciones  Neuronas                                             Salida  \\\n",
              "0            5.0       2.0  [[0.005649813450872898], [0.4390484690666199],...   \n",
              "1           10.0       2.0  [[0.021755153313279152], [0.44149813055992126]...   \n",
              "2           15.0       2.0  [[0.04698999971151352], [0.4456677734851837], ...   \n",
              "3           20.0       2.0  [[0.07840099185705185], [0.4515784978866577], ...   \n",
              "4           25.0       2.0  [[0.11369755864143372], [0.45896583795547485],...   \n",
              "5           30.0       2.0  [[0.1512230634689331], [0.4671897888183594], [...   \n",
              "6           35.0       2.0  [[0.18957825005054474], [0.47563135623931885],...   \n",
              "7           40.0       2.0  [[0.2275083065032959], [0.48381274938583374], ...   \n",
              "8           45.0       2.0  [[0.2639109492301941], [0.4913235902786255], [...   \n",
              "9           50.0       2.0  [[0.2978973388671875], [0.4978470206260681], [...   \n",
              "10          55.0       2.0  [[0.32883644104003906], [0.5031951665878296], ...   \n",
              "11          60.0       2.0  [[0.356362909078598], [0.5073092579841614], [0...   \n",
              "12          65.0       2.0  [[0.3803562521934509], [0.510240375995636], [0...   \n",
              "13          70.0       2.0  [[0.40089815855026245], [0.512117862701416], [...   \n",
              "14          75.0       2.0  [[0.4182194471359253], [0.5131163597106934], [...   \n",
              "15          80.0       2.0  [[0.43264487385749817], [0.5134252309799194], ...   \n",
              "16          85.0       2.0  [[0.44454389810562134], [0.5132258534431458], ...   \n",
              "17          90.0       2.0  [[0.45429182052612305], [0.5126770734786987], ...   \n",
              "18          95.0       2.0  [[0.46224305033683777], [0.5119084715843201], ...   \n",
              "19         100.0       2.0  [[0.46871548891067505], [0.5110200047492981], ...   \n",
              "20           5.0       2.0  [[0.5047749876976013], [0.2591114044189453], [...   \n",
              "21          10.0       2.0  [[0.5178146958351135], [0.30061638355255127], ...   \n",
              "22          15.0       2.0  [[0.5357535481452942], [0.358674556016922], [0...   \n",
              "23          20.0       2.0  [[0.5534332394599915], [0.415172278881073], [0...   \n",
              "24          25.0       2.0  [[0.5672420859336853], [0.4592672288417816], [...   \n",
              "25          30.0       2.0  [[0.5758261680603027], [0.48982664942741394], ...   \n",
              "26          35.0       2.0  [[0.5793712139129639], [0.5100425481796265], [...   \n",
              "27          40.0       2.0  [[0.5786272883415222], [0.5235466957092285], [...   \n",
              "28          45.0       2.0  [[0.5743822455406189], [0.533412516117096], [0...   \n",
              "29          50.0       2.0  [[0.5672374367713928], [0.5411506295204163], [...   \n",
              "30          55.0       2.0  [[0.5596895813941956], [0.5496538281440735], [...   \n",
              "31          60.0       2.0  [[0.5535033941268921], [0.5535033941268921], [...   \n",
              "32          65.0       2.0  [[0.5517939925193787], [0.5517939925193787], [...   \n",
              "33          70.0       2.0  [[0.5544360876083374], [0.554331362247467], [0...   \n",
              "34          75.0       2.0  [[0.5599936842918396], [0.5599936842918396], [...   \n",
              "35          80.0       2.0  [[0.5672759413719177], [0.5672759413719177], [...   \n",
              "36          85.0       2.0  [[0.5754673480987549], [0.5754673480987549], [...   \n",
              "37          90.0       2.0  [[0.5840373039245605], [0.5840223431587219], [...   \n",
              "38          95.0       2.0  [[0.5926087498664856], [0.5926087498664856], [...   \n",
              "39         100.0       2.0  [[0.6009394526481628], [0.600856602191925], [0...   \n",
              "40           5.0       2.0  [[0.006364747881889343], [0.0], [0.22652055323...   \n",
              "41          10.0       2.0  [[0.13973581790924072], [0.0], [0.387369453907...   \n",
              "42          15.0       2.0  [[0.2661535143852234], [0.03796519339084625], ...   \n",
              "43          20.0       2.0  [[0.4442352056503296], [0.2627373933792114], [...   \n",
              "44          25.0       2.0  [[0.45918041467666626], [0.30963850021362305],...   \n",
              "45          30.0       2.0  [[0.4427093267440796], [0.3187970519065857], [...   \n",
              "46          35.0       2.0  [[0.44703978300094604], [0.3486960232257843], ...   \n",
              "47          40.0       2.0  [[0.4471415579319], [0.37066733837127686], [0....   \n",
              "48          45.0       2.0  [[0.44736963510513306], [0.39013341069221497],...   \n",
              "49          50.0       2.0  [[0.4471046030521393], [0.40677961707115173], ...   \n",
              "50          55.0       2.0  [[0.4463666081428528], [0.4210107624530792], [...   \n",
              "51          60.0       2.0  [[0.44509798288345337], [0.4331253170967102], ...   \n",
              "52          65.0       2.0  [[0.4432491362094879], [0.44342315196990967], ...   \n",
              "53          70.0       2.0  [[0.4407733678817749], [0.4522210359573364], [...   \n",
              "54          75.0       2.0  [[0.4376194179058075], [0.45987385511398315], ...   \n",
              "55          80.0       2.0  [[0.43370527029037476], [0.4667895436286926], ...   \n",
              "56          85.0       2.0  [[0.4288676679134369], [0.4734230041503906], [...   \n",
              "57          90.0       2.0  [[0.42280590534210205], [0.48026347160339355],...   \n",
              "58          95.0       2.0  [[0.41505420207977295], [0.4878312349319458], ...   \n",
              "59         100.0       2.0  [[0.4050311744213104], [0.4966951310634613], [...   \n",
              "60           5.0       2.0  [[0.6606554388999939], [0.7199755311012268], [...   \n",
              "61          10.0       2.0  [[0.6277593970298767], [0.6875156760215759], [...   \n",
              "62          15.0       2.0  [[0.5835110545158386], [0.6425291895866394], [...   \n",
              "63          20.0       2.0  [[0.5411472320556641], [0.5979224443435669], [...   \n",
              "64          25.0       2.0  [[0.50775146484375], [0.5617885589599609], [0....   \n",
              "65          30.0       2.0  [[0.4851781129837036], [0.5374282002449036], [...   \n",
              "66          35.0       2.0  [[0.4716605544090271], [0.5247731804847717], [...   \n",
              "67          40.0       2.0  [[0.46317240595817566], [0.5213796496391296], ...   \n",
              "68          45.0       2.0  [[0.45552384853363037], [0.5230821371078491], ...   \n",
              "69          50.0       2.0  [[0.44648221135139465], [0.5260435342788696], ...   \n",
              "70          55.0       2.0  [[0.4358774423599243], [0.5287933945655823], [...   \n",
              "71          60.0       2.0  [[0.4238091707229614], [0.5318737030029297], [...   \n",
              "72          65.0       2.0  [[0.40985003113746643], [0.5362168550491333], ...   \n",
              "73          70.0       2.0  [[0.39382675290107727], [0.542341947555542], [...   \n",
              "74          75.0       2.0  [[0.3760530352592468], [0.5501248240470886], [...   \n",
              "75          80.0       2.0  [[0.3569796085357666], [0.5590261816978455], [...   \n",
              "76          85.0       2.0  [[0.33712315559387207], [0.5684870481491089], ...   \n",
              "77          90.0       2.0  [[0.3170223832130432], [0.5780631899833679], [...   \n",
              "78          95.0       2.0  [[0.2971668541431427], [0.5874120593070984], [...   \n",
              "79         100.0       2.0  [[0.2779511511325836], [0.5962730050086975], [...   \n",
              "80           5.0       3.0  [[0.02499573864042759], [0.07734305411577225],...   \n",
              "81          10.0       3.0  [[0.09733346849679947], [0.20647813379764557],...   \n",
              "82          15.0       3.0  [[0.19869057834148407], [0.38957130908966064],...   \n",
              "83          20.0       3.0  [[0.2698918581008911], [0.4941309094429016], [...   \n",
              "84          25.0       3.0  [[0.29156380891799927], [0.48005247116088867],...   \n",
              "85          30.0       3.0  [[0.315219908952713], [0.4767000675201416], [0...   \n",
              "86          35.0       3.0  [[0.3408297896385193], [0.4827424883842468], [...   \n",
              "87          40.0       3.0  [[0.36257079243659973], [0.4860028922557831], ...   \n",
              "88          45.0       3.0  [[0.3817104399204254], [0.4889407753944397], [...   \n",
              "89          50.0       3.0  [[0.39832502603530884], [0.4913879632949829], ...   \n",
              "90          55.0       3.0  [[0.4126506745815277], [0.49338865280151367], ...   \n",
              "91          60.0       3.0  [[0.4249469041824341], [0.49500036239624023], ...   \n",
              "92          65.0       3.0  [[0.4354710578918457], [0.496282160282135], [0...   \n",
              "93          70.0       3.0  [[0.4444648027420044], [0.49728989601135254], ...   \n",
              "94          75.0       3.0  [[0.4521474838256836], [0.4980737566947937], [...   \n",
              "95          80.0       3.0  [[0.4587133526802063], [0.4986768662929535], [...   \n",
              "96          85.0       3.0  [[0.4643316864967346], [0.49913543462753296], ...   \n",
              "97          90.0       3.0  [[0.4691484570503235], [0.4994795322418213], [...   \n",
              "98          95.0       3.0  [[0.473288357257843], [0.49973371624946594], [...   \n",
              "99         100.0       3.0  [[0.4768570065498352], [0.49991750717163086], ...   \n",
              "100          5.0       3.0  [[0.4941248297691345], [0.7322025299072266], [...   \n",
              "101         10.0       3.0  [[0.47853270173072815], [0.7343856692314148], ...   \n",
              "102         15.0       3.0  [[0.45822474360466003], [0.7481694221496582], ...   \n",
              "103         20.0       3.0  [[0.4389854967594147], [0.7639818787574768], [...   \n",
              "104         25.0       3.0  [[0.4199272394180298], [0.780537486076355], [0...   \n",
              "105         30.0       3.0  [[0.40020740032196045], [0.7952300310134888], ...   \n",
              "106         35.0       3.0  [[0.37945932149887085], [0.8086078763008118], ...   \n",
              "107         40.0       3.0  [[0.35824838280677795], [0.820104718208313], [...   \n",
              "108         45.0       3.0  [[0.33727380633354187], [0.8319783210754395], ...   \n",
              "109         50.0       3.0  [[0.3168109059333801], [0.8431638479232788], [...   \n",
              "110         55.0       3.0  [[0.2957448661327362], [0.8527189493179321], [...   \n",
              "111         60.0       3.0  [[0.2751430571079254], [0.8613719344139099], [...   \n",
              "112         65.0       3.0  [[0.2554073631763458], [0.8700038194656372], [...   \n",
              "113         70.0       3.0  [[0.23730608820915222], [0.8784527778625488], ...   \n",
              "114         75.0       3.0  [[0.22049076855182648], [0.8866870999336243], ...   \n",
              "115         80.0       3.0  [[0.20490805804729462], [0.8941521644592285], ...   \n",
              "116         85.0       3.0  [[0.19078372418880463], [0.9015907049179077], ...   \n",
              "117         90.0       3.0  [[0.17781463265419006], [0.9084599614143372], ...   \n",
              "118         95.0       3.0  [[0.16593821346759796], [0.9148118495941162], ...   \n",
              "119        100.0       3.0  [[0.15503494441509247], [0.9206464290618896], ...   \n",
              "120          5.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "121         10.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "122         15.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "123         20.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "124         25.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "125         30.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "126         35.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "127         40.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "128         45.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "129         50.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "130         55.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "131         60.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "132         65.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "133         70.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "134         75.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "135         80.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "136         85.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "137         90.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "138         95.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "139        100.0       3.0                       [[0.0], [0.0], [0.0], [0.0]]   \n",
              "140          5.0       3.0  [[0.37372806668281555], [0.3304220736026764], ...   \n",
              "141         10.0       3.0  [[0.4179372191429138], [0.38004088401794434], ...   \n",
              "142         15.0       3.0  [[0.4720408618450165], [0.44226449728012085], ...   \n",
              "143         20.0       3.0  [[0.5059539079666138], [0.4828922152519226], [...   \n",
              "144         25.0       3.0  [[0.5122794508934021], [0.4929869472980499], [...   \n",
              "145         30.0       3.0  [[0.5088165402412415], [0.4923112988471985], [...   \n",
              "146         35.0       3.0  [[0.5065699815750122], [0.49308183789253235], ...   \n",
              "147         40.0       3.0  [[0.5051019787788391], [0.4947560727596283], [...   \n",
              "148         45.0       3.0  [[0.503477931022644], [0.49630388617515564], [...   \n",
              "149         50.0       3.0  [[0.501632571220398], [0.49772530794143677], [...   \n",
              "150         55.0       3.0  [[0.4994085431098938], [0.4990040957927704], [...   \n",
              "151         60.0       3.0  [[0.49653175473213196], [0.5001164078712463], ...   \n",
              "152         65.0       3.0  [[0.49263283610343933], [0.5010842680931091], ...   \n",
              "153         70.0       3.0  [[0.48734650015830994], [0.5020850896835327], ...   \n",
              "154         75.0       3.0  [[0.4803944528102875], [0.5035218000411987], [...   \n",
              "155         80.0       3.0  [[0.4714545011520386], [0.5058317184448242], [...   \n",
              "156         85.0       3.0  [[0.4601162075996399], [0.5094026327133179], [...   \n",
              "157         90.0       3.0  [[0.4466138482093811], [0.5148274302482605], [...   \n",
              "158         95.0       3.0  [[0.4325069487094879], [0.5225852131843567], [...   \n",
              "159        100.0       3.0  [[0.4196690320968628], [0.5324796438217163], [...   \n",
              "\n",
              "        Error       Configuraci贸n  \n",
              "0    0.336104        [relu, relu]  \n",
              "1    0.330586        [relu, relu]  \n",
              "2    0.322351        [relu, relu]  \n",
              "3    0.312806        [relu, relu]  \n",
              "4    0.302969        [relu, relu]  \n",
              "5    0.293474        [relu, relu]  \n",
              "6    0.284756        [relu, relu]  \n",
              "7    0.277100        [relu, relu]  \n",
              "8    0.270646        [relu, relu]  \n",
              "9    0.265403        [relu, relu]  \n",
              "10   0.261284        [relu, relu]  \n",
              "11   0.258142        [relu, relu]  \n",
              "12   0.255807        [relu, relu]  \n",
              "13   0.254106        [relu, relu]  \n",
              "14   0.252889        [relu, relu]  \n",
              "15   0.252029        [relu, relu]  \n",
              "16   0.251425        [relu, relu]  \n",
              "17   0.251004        [relu, relu]  \n",
              "18   0.250711        [relu, relu]  \n",
              "19   0.250506        [relu, relu]  \n",
              "20   0.328934     [relu, sigmoid]  \n",
              "21   0.305383     [relu, sigmoid]  \n",
              "22   0.277802     [relu, sigmoid]  \n",
              "23   0.257419     [relu, sigmoid]  \n",
              "24   0.245957     [relu, sigmoid]  \n",
              "25   0.239830     [relu, sigmoid]  \n",
              "26   0.235799     [relu, sigmoid]  \n",
              "27   0.232112     [relu, sigmoid]  \n",
              "28   0.227929     [relu, sigmoid]  \n",
              "29   0.223062     [relu, sigmoid]  \n",
              "30   0.218101     [relu, sigmoid]  \n",
              "31   0.213191     [relu, sigmoid]  \n",
              "32   0.208998     [relu, sigmoid]  \n",
              "33   0.204827     [relu, sigmoid]  \n",
              "34   0.200693     [relu, sigmoid]  \n",
              "35   0.196652     [relu, sigmoid]  \n",
              "36   0.192793     [relu, sigmoid]  \n",
              "37   0.189185     [relu, sigmoid]  \n",
              "38   0.185902     [relu, sigmoid]  \n",
              "39   0.182956     [relu, sigmoid]  \n",
              "40   0.399860     [sigmoid, relu]  \n",
              "41   0.357449     [sigmoid, relu]  \n",
              "42   0.328309     [sigmoid, relu]  \n",
              "43   0.281944     [sigmoid, relu]  \n",
              "44   0.274103     [sigmoid, relu]  \n",
              "45   0.266963     [sigmoid, relu]  \n",
              "46   0.261552     [sigmoid, relu]  \n",
              "47   0.257340     [sigmoid, relu]  \n",
              "48   0.254034     [sigmoid, relu]  \n",
              "49   0.251391     [sigmoid, relu]  \n",
              "50   0.249210     [sigmoid, relu]  \n",
              "51   0.247311     [sigmoid, relu]  \n",
              "52   0.245535     [sigmoid, relu]  \n",
              "53   0.243736     [sigmoid, relu]  \n",
              "54   0.241777     [sigmoid, relu]  \n",
              "55   0.239533     [sigmoid, relu]  \n",
              "56   0.236889     [sigmoid, relu]  \n",
              "57   0.233718     [sigmoid, relu]  \n",
              "58   0.229855     [sigmoid, relu]  \n",
              "59   0.225058     [sigmoid, relu]  \n",
              "60   0.290811  [sigmoid, sigmoid]  \n",
              "61   0.278880  [sigmoid, sigmoid]  \n",
              "62   0.265879  [sigmoid, sigmoid]  \n",
              "63   0.256897  [sigmoid, sigmoid]  \n",
              "64   0.252386  [sigmoid, sigmoid]  \n",
              "65   0.250619  [sigmoid, sigmoid]  \n",
              "66   0.249864  [sigmoid, sigmoid]  \n",
              "67   0.249039  [sigmoid, sigmoid]  \n",
              "68   0.247516  [sigmoid, sigmoid]  \n",
              "69   0.245073  [sigmoid, sigmoid]  \n",
              "70   0.241953  [sigmoid, sigmoid]  \n",
              "71   0.238476  [sigmoid, sigmoid]  \n",
              "72   0.234717  [sigmoid, sigmoid]  \n",
              "73   0.230639  [sigmoid, sigmoid]  \n",
              "74   0.226267  [sigmoid, sigmoid]  \n",
              "75   0.221709  [sigmoid, sigmoid]  \n",
              "76   0.217110  [sigmoid, sigmoid]  \n",
              "77   0.212611  [sigmoid, sigmoid]  \n",
              "78   0.208325  [sigmoid, sigmoid]  \n",
              "79   0.204325  [sigmoid, sigmoid]  \n",
              "80   0.435990        [relu, relu]  \n",
              "81   0.349303        [relu, relu]  \n",
              "82   0.282070        [relu, relu]  \n",
              "83   0.271265        [relu, relu]  \n",
              "84   0.266063        [relu, relu]  \n",
              "85   0.262278        [relu, relu]  \n",
              "86   0.259302        [relu, relu]  \n",
              "87   0.257001        [relu, relu]  \n",
              "88   0.255245        [relu, relu]  \n",
              "89   0.253920        [relu, relu]  \n",
              "90   0.252928        [relu, relu]  \n",
              "91   0.252187        [relu, relu]  \n",
              "92   0.251636        [relu, relu]  \n",
              "93   0.251225        [relu, relu]  \n",
              "94   0.250920        [relu, relu]  \n",
              "95   0.250692        [relu, relu]  \n",
              "96   0.250522        [relu, relu]  \n",
              "97   0.250394        [relu, relu]  \n",
              "98   0.250298        [relu, relu]  \n",
              "99   0.250226        [relu, relu]  \n",
              "100  0.206694     [relu, sigmoid]  \n",
              "101  0.199436     [relu, sigmoid]  \n",
              "102  0.189715     [relu, sigmoid]  \n",
              "103  0.178374     [relu, sigmoid]  \n",
              "104  0.164699     [relu, sigmoid]  \n",
              "105  0.149029     [relu, sigmoid]  \n",
              "106  0.132092     [relu, sigmoid]  \n",
              "107  0.114908     [relu, sigmoid]  \n",
              "108  0.098202     [relu, sigmoid]  \n",
              "109  0.082953     [relu, sigmoid]  \n",
              "110  0.069945     [relu, sigmoid]  \n",
              "111  0.059085     [relu, sigmoid]  \n",
              "112  0.049979     [relu, sigmoid]  \n",
              "113  0.042412     [relu, sigmoid]  \n",
              "114  0.036109     [relu, sigmoid]  \n",
              "115  0.030830     [relu, sigmoid]  \n",
              "116  0.026409     [relu, sigmoid]  \n",
              "117  0.022704     [relu, sigmoid]  \n",
              "118  0.019582     [relu, sigmoid]  \n",
              "119  0.016949     [relu, sigmoid]  \n",
              "120  0.500000     [sigmoid, relu]  \n",
              "121  0.500000     [sigmoid, relu]  \n",
              "122  0.500000     [sigmoid, relu]  \n",
              "123  0.500000     [sigmoid, relu]  \n",
              "124  0.500000     [sigmoid, relu]  \n",
              "125  0.500000     [sigmoid, relu]  \n",
              "126  0.500000     [sigmoid, relu]  \n",
              "127  0.500000     [sigmoid, relu]  \n",
              "128  0.500000     [sigmoid, relu]  \n",
              "129  0.500000     [sigmoid, relu]  \n",
              "130  0.500000     [sigmoid, relu]  \n",
              "131  0.500000     [sigmoid, relu]  \n",
              "132  0.500000     [sigmoid, relu]  \n",
              "133  0.500000     [sigmoid, relu]  \n",
              "134  0.500000     [sigmoid, relu]  \n",
              "135  0.500000     [sigmoid, relu]  \n",
              "136  0.500000     [sigmoid, relu]  \n",
              "137  0.500000     [sigmoid, relu]  \n",
              "138  0.500000     [sigmoid, relu]  \n",
              "139  0.500000     [sigmoid, relu]  \n",
              "140  0.273140  [sigmoid, sigmoid]  \n",
              "141  0.261042  [sigmoid, sigmoid]  \n",
              "142  0.252413  [sigmoid, sigmoid]  \n",
              "143  0.250493  [sigmoid, sigmoid]  \n",
              "144  0.250359  [sigmoid, sigmoid]  \n",
              "145  0.250239  [sigmoid, sigmoid]  \n",
              "146  0.250133  [sigmoid, sigmoid]  \n",
              "147  0.250030  [sigmoid, sigmoid]  \n",
              "148  0.249918  [sigmoid, sigmoid]  \n",
              "149  0.249776  [sigmoid, sigmoid]  \n",
              "150  0.249561  [sigmoid, sigmoid]  \n",
              "151  0.249186  [sigmoid, sigmoid]  \n",
              "152  0.248498  [sigmoid, sigmoid]  \n",
              "153  0.247300  [sigmoid, sigmoid]  \n",
              "154  0.245422  [sigmoid, sigmoid]  \n",
              "155  0.242735  [sigmoid, sigmoid]  \n",
              "156  0.239081  [sigmoid, sigmoid]  \n",
              "157  0.234266  [sigmoid, sigmoid]  \n",
              "158  0.228142  [sigmoid, sigmoid]  \n",
              "159  0.220564  [sigmoid, sigmoid]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d940b60c-fb2a-4fdb-9dc2-83f49124b471\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteraciones</th>\n",
              "      <th>Neuronas</th>\n",
              "      <th>Salida</th>\n",
              "      <th>Error</th>\n",
              "      <th>Configuraci贸n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.005649813450872898], [0.4390484690666199],...</td>\n",
              "      <td>0.336104</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.021755153313279152], [0.44149813055992126]...</td>\n",
              "      <td>0.330586</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.04698999971151352], [0.4456677734851837], ...</td>\n",
              "      <td>0.322351</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.07840099185705185], [0.4515784978866577], ...</td>\n",
              "      <td>0.312806</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.11369755864143372], [0.45896583795547485],...</td>\n",
              "      <td>0.302969</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.1512230634689331], [0.4671897888183594], [...</td>\n",
              "      <td>0.293474</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.18957825005054474], [0.47563135623931885],...</td>\n",
              "      <td>0.284756</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2275083065032959], [0.48381274938583374], ...</td>\n",
              "      <td>0.277100</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2639109492301941], [0.4913235902786255], [...</td>\n",
              "      <td>0.270646</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2978973388671875], [0.4978470206260681], [...</td>\n",
              "      <td>0.265403</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.32883644104003906], [0.5031951665878296], ...</td>\n",
              "      <td>0.261284</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.356362909078598], [0.5073092579841614], [0...</td>\n",
              "      <td>0.258142</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.3803562521934509], [0.510240375995636], [0...</td>\n",
              "      <td>0.255807</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>70.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.40089815855026245], [0.512117862701416], [...</td>\n",
              "      <td>0.254106</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>75.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4182194471359253], [0.5131163597106934], [...</td>\n",
              "      <td>0.252889</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.43264487385749817], [0.5134252309799194], ...</td>\n",
              "      <td>0.252029</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>85.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.44454389810562134], [0.5132258534431458], ...</td>\n",
              "      <td>0.251425</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>90.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.45429182052612305], [0.5126770734786987], ...</td>\n",
              "      <td>0.251004</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>95.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.46224305033683777], [0.5119084715843201], ...</td>\n",
              "      <td>0.250711</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.46871548891067505], [0.5110200047492981], ...</td>\n",
              "      <td>0.250506</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5047749876976013], [0.2591114044189453], [...</td>\n",
              "      <td>0.328934</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5178146958351135], [0.30061638355255127], ...</td>\n",
              "      <td>0.305383</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5357535481452942], [0.358674556016922], [0...</td>\n",
              "      <td>0.277802</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5534332394599915], [0.415172278881073], [0...</td>\n",
              "      <td>0.257419</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5672420859336853], [0.4592672288417816], [...</td>\n",
              "      <td>0.245957</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>30.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5758261680603027], [0.48982664942741394], ...</td>\n",
              "      <td>0.239830</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>35.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5793712139129639], [0.5100425481796265], [...</td>\n",
              "      <td>0.235799</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5786272883415222], [0.5235466957092285], [...</td>\n",
              "      <td>0.232112</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5743822455406189], [0.533412516117096], [0...</td>\n",
              "      <td>0.227929</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5672374367713928], [0.5411506295204163], [...</td>\n",
              "      <td>0.223062</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5596895813941956], [0.5496538281440735], [...</td>\n",
              "      <td>0.218101</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5535033941268921], [0.5535033941268921], [...</td>\n",
              "      <td>0.213191</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5517939925193787], [0.5517939925193787], [...</td>\n",
              "      <td>0.208998</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>70.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5544360876083374], [0.554331362247467], [0...</td>\n",
              "      <td>0.204827</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>75.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5599936842918396], [0.5599936842918396], [...</td>\n",
              "      <td>0.200693</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5672759413719177], [0.5672759413719177], [...</td>\n",
              "      <td>0.196652</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>85.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5754673480987549], [0.5754673480987549], [...</td>\n",
              "      <td>0.192793</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>90.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5840373039245605], [0.5840223431587219], [...</td>\n",
              "      <td>0.189185</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>95.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5926087498664856], [0.5926087498664856], [...</td>\n",
              "      <td>0.185902</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.6009394526481628], [0.600856602191925], [0...</td>\n",
              "      <td>0.182956</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.006364747881889343], [0.0], [0.22652055323...</td>\n",
              "      <td>0.399860</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.13973581790924072], [0.0], [0.387369453907...</td>\n",
              "      <td>0.357449</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2661535143852234], [0.03796519339084625], ...</td>\n",
              "      <td>0.328309</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4442352056503296], [0.2627373933792114], [...</td>\n",
              "      <td>0.281944</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.45918041467666626], [0.30963850021362305],...</td>\n",
              "      <td>0.274103</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>30.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4427093267440796], [0.3187970519065857], [...</td>\n",
              "      <td>0.266963</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>35.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.44703978300094604], [0.3486960232257843], ...</td>\n",
              "      <td>0.261552</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4471415579319], [0.37066733837127686], [0....</td>\n",
              "      <td>0.257340</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.44736963510513306], [0.39013341069221497],...</td>\n",
              "      <td>0.254034</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4471046030521393], [0.40677961707115173], ...</td>\n",
              "      <td>0.251391</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4463666081428528], [0.4210107624530792], [...</td>\n",
              "      <td>0.249210</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.44509798288345337], [0.4331253170967102], ...</td>\n",
              "      <td>0.247311</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4432491362094879], [0.44342315196990967], ...</td>\n",
              "      <td>0.245535</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>70.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4407733678817749], [0.4522210359573364], [...</td>\n",
              "      <td>0.243736</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>75.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4376194179058075], [0.45987385511398315], ...</td>\n",
              "      <td>0.241777</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.43370527029037476], [0.4667895436286926], ...</td>\n",
              "      <td>0.239533</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>85.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4288676679134369], [0.4734230041503906], [...</td>\n",
              "      <td>0.236889</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>90.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.42280590534210205], [0.48026347160339355],...</td>\n",
              "      <td>0.233718</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>95.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.41505420207977295], [0.4878312349319458], ...</td>\n",
              "      <td>0.229855</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4050311744213104], [0.4966951310634613], [...</td>\n",
              "      <td>0.225058</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.6606554388999939], [0.7199755311012268], [...</td>\n",
              "      <td>0.290811</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.6277593970298767], [0.6875156760215759], [...</td>\n",
              "      <td>0.278880</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5835110545158386], [0.6425291895866394], [...</td>\n",
              "      <td>0.265879</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.5411472320556641], [0.5979224443435669], [...</td>\n",
              "      <td>0.256897</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.50775146484375], [0.5617885589599609], [0....</td>\n",
              "      <td>0.252386</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>30.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4851781129837036], [0.5374282002449036], [...</td>\n",
              "      <td>0.250619</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>35.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4716605544090271], [0.5247731804847717], [...</td>\n",
              "      <td>0.249864</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.46317240595817566], [0.5213796496391296], ...</td>\n",
              "      <td>0.249039</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.45552384853363037], [0.5230821371078491], ...</td>\n",
              "      <td>0.247516</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.44648221135139465], [0.5260435342788696], ...</td>\n",
              "      <td>0.245073</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>55.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4358774423599243], [0.5287933945655823], [...</td>\n",
              "      <td>0.241953</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.4238091707229614], [0.5318737030029297], [...</td>\n",
              "      <td>0.238476</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.40985003113746643], [0.5362168550491333], ...</td>\n",
              "      <td>0.234717</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>70.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.39382675290107727], [0.542341947555542], [...</td>\n",
              "      <td>0.230639</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>75.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.3760530352592468], [0.5501248240470886], [...</td>\n",
              "      <td>0.226267</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.3569796085357666], [0.5590261816978455], [...</td>\n",
              "      <td>0.221709</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>85.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.33712315559387207], [0.5684870481491089], ...</td>\n",
              "      <td>0.217110</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>90.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.3170223832130432], [0.5780631899833679], [...</td>\n",
              "      <td>0.212611</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>95.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2971668541431427], [0.5874120593070984], [...</td>\n",
              "      <td>0.208325</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[0.2779511511325836], [0.5962730050086975], [...</td>\n",
              "      <td>0.204325</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.02499573864042759], [0.07734305411577225],...</td>\n",
              "      <td>0.435990</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.09733346849679947], [0.20647813379764557],...</td>\n",
              "      <td>0.349303</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.19869057834148407], [0.38957130908966064],...</td>\n",
              "      <td>0.282070</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.2698918581008911], [0.4941309094429016], [...</td>\n",
              "      <td>0.271265</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.29156380891799927], [0.48005247116088867],...</td>\n",
              "      <td>0.266063</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.315219908952713], [0.4767000675201416], [0...</td>\n",
              "      <td>0.262278</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.3408297896385193], [0.4827424883842468], [...</td>\n",
              "      <td>0.259302</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.36257079243659973], [0.4860028922557831], ...</td>\n",
              "      <td>0.257001</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>45.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.3817104399204254], [0.4889407753944397], [...</td>\n",
              "      <td>0.255245</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.39832502603530884], [0.4913879632949829], ...</td>\n",
              "      <td>0.253920</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>55.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4126506745815277], [0.49338865280151367], ...</td>\n",
              "      <td>0.252928</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4249469041824341], [0.49500036239624023], ...</td>\n",
              "      <td>0.252187</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4354710578918457], [0.496282160282135], [0...</td>\n",
              "      <td>0.251636</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4444648027420044], [0.49728989601135254], ...</td>\n",
              "      <td>0.251225</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4521474838256836], [0.4980737566947937], [...</td>\n",
              "      <td>0.250920</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>80.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4587133526802063], [0.4986768662929535], [...</td>\n",
              "      <td>0.250692</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>85.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4643316864967346], [0.49913543462753296], ...</td>\n",
              "      <td>0.250522</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4691484570503235], [0.4994795322418213], [...</td>\n",
              "      <td>0.250394</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>95.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.473288357257843], [0.49973371624946594], [...</td>\n",
              "      <td>0.250298</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4768570065498352], [0.49991750717163086], ...</td>\n",
              "      <td>0.250226</td>\n",
              "      <td>[relu, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4941248297691345], [0.7322025299072266], [...</td>\n",
              "      <td>0.206694</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.47853270173072815], [0.7343856692314148], ...</td>\n",
              "      <td>0.199436</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.45822474360466003], [0.7481694221496582], ...</td>\n",
              "      <td>0.189715</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4389854967594147], [0.7639818787574768], [...</td>\n",
              "      <td>0.178374</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4199272394180298], [0.780537486076355], [0...</td>\n",
              "      <td>0.164699</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.40020740032196045], [0.7952300310134888], ...</td>\n",
              "      <td>0.149029</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.37945932149887085], [0.8086078763008118], ...</td>\n",
              "      <td>0.132092</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.35824838280677795], [0.820104718208313], [...</td>\n",
              "      <td>0.114908</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>45.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.33727380633354187], [0.8319783210754395], ...</td>\n",
              "      <td>0.098202</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.3168109059333801], [0.8431638479232788], [...</td>\n",
              "      <td>0.082953</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>55.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.2957448661327362], [0.8527189493179321], [...</td>\n",
              "      <td>0.069945</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.2751430571079254], [0.8613719344139099], [...</td>\n",
              "      <td>0.059085</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.2554073631763458], [0.8700038194656372], [...</td>\n",
              "      <td>0.049979</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.23730608820915222], [0.8784527778625488], ...</td>\n",
              "      <td>0.042412</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.22049076855182648], [0.8866870999336243], ...</td>\n",
              "      <td>0.036109</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>80.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.20490805804729462], [0.8941521644592285], ...</td>\n",
              "      <td>0.030830</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>85.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.19078372418880463], [0.9015907049179077], ...</td>\n",
              "      <td>0.026409</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.17781463265419006], [0.9084599614143372], ...</td>\n",
              "      <td>0.022704</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>95.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.16593821346759796], [0.9148118495941162], ...</td>\n",
              "      <td>0.019582</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.15503494441509247], [0.9206464290618896], ...</td>\n",
              "      <td>0.016949</td>\n",
              "      <td>[relu, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>45.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>55.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>80.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>85.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>95.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.0], [0.0], [0.0], [0.0]]</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>[sigmoid, relu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.37372806668281555], [0.3304220736026764], ...</td>\n",
              "      <td>0.273140</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4179372191429138], [0.38004088401794434], ...</td>\n",
              "      <td>0.261042</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4720408618450165], [0.44226449728012085], ...</td>\n",
              "      <td>0.252413</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.5059539079666138], [0.4828922152519226], [...</td>\n",
              "      <td>0.250493</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.5122794508934021], [0.4929869472980499], [...</td>\n",
              "      <td>0.250359</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.5088165402412415], [0.4923112988471985], [...</td>\n",
              "      <td>0.250239</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.5065699815750122], [0.49308183789253235], ...</td>\n",
              "      <td>0.250133</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.5051019787788391], [0.4947560727596283], [...</td>\n",
              "      <td>0.250030</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>45.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.503477931022644], [0.49630388617515564], [...</td>\n",
              "      <td>0.249918</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.501632571220398], [0.49772530794143677], [...</td>\n",
              "      <td>0.249776</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>55.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4994085431098938], [0.4990040957927704], [...</td>\n",
              "      <td>0.249561</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.49653175473213196], [0.5001164078712463], ...</td>\n",
              "      <td>0.249186</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>65.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.49263283610343933], [0.5010842680931091], ...</td>\n",
              "      <td>0.248498</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.48734650015830994], [0.5020850896835327], ...</td>\n",
              "      <td>0.247300</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>75.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4803944528102875], [0.5035218000411987], [...</td>\n",
              "      <td>0.245422</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>80.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4714545011520386], [0.5058317184448242], [...</td>\n",
              "      <td>0.242735</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>85.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4601162075996399], [0.5094026327133179], [...</td>\n",
              "      <td>0.239081</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4466138482093811], [0.5148274302482605], [...</td>\n",
              "      <td>0.234266</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>95.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4325069487094879], [0.5225852131843567], [...</td>\n",
              "      <td>0.228142</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[[0.4196690320968628], [0.5324796438217163], [...</td>\n",
              "      <td>0.220564</td>\n",
              "      <td>[sigmoid, sigmoid]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d940b60c-fb2a-4fdb-9dc2-83f49124b471')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d940b60c-fb2a-4fdb-9dc2-83f49124b471 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d940b60c-fb2a-4fdb-9dc2-83f49124b471');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}